{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gobot md yaml configs tutorial.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPy9fJMSaAjzuzydAC4Gs24",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/oserikov/88cec7c0025e69986a8ce68efd7d45c9/gobot-md-yaml-configs-tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jj5nbxnPbz6D",
        "colab_type": "text"
      },
      "source": [
        "# Use RASA DSL to Configure DeepPavlov's GO-Bot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRO97JLXb8j5",
        "colab_type": "text"
      },
      "source": [
        "At DeepPavlov, we support a variety of industry-wide and popular standards to support developing Conversational AI solutions.\n",
        "DSLs, known as Domain-Specific Languages, provide a rich mechanism to define the behavior, or \"the what\", while,\n",
        "the underlying system uses the parser to transform these definitions into commands that implement this behavior, or \"the how\"\n", 
        "using the system's components.",
        "\n",
        "Until very recently we supported two such DSLs, including industry-standard <a href=\"http://docs.deeppavlov.ai/en/master/features/skills/aiml_skill.html\">AIML</a>, as well as <a href=\"http://docs.deeppavlov.ai/en/master/features/skills/dsl_skill.html\">DSL</a> designed by one our partners, EORA.\n",
        "\n",
        "In this tutorial, you will learn how to use another industrial DSL, or, better said, set of DSLs, introduced by RASA.ai,\n",
        "to build simple goal-oriented chatbots using DeepPavlov's GO-bot.\n",
        "\n",
        "As discussed in our blog post, this is the very beginning of our work focused on supporting RASA DSLs as a way to configure DeepPavlov-based\n",
        "goal-oriented chatbots, and therefore \n",
        "\n",
        "To configure a DeepPavlov-based goal-oriented chatbot using these DSLs, you need to have at least three basic config files:\n",
        "* `stories.md` (or `stories-{trn, tst, val}.md` but these are just subsamples)\n",
        "* `nlu.md`\n",
        "* `domain.yml`\n",
        "\n",
        "These files allow you to define 3 key elements of the chatbot, including product-level stories, NLU training data, and your chatbot's domain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWP08HJGnCDo",
        "colab_type": "text"
      },
      "source": [
        "## Concepts Behind Stories.md, NLU.md, and Domain.yml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_NQHZOqcwcr",
        "colab_type": "text"
      },
      "source": [
        "### `stories.md`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3HWMZPrg4V1",
        "colab_type": "text"
      },
      "source": [
        "`stories.md` is a mechanism used to teach your chatbot how to respond to user messages. It allows you to control your chatbot's dialog management.\n",
        "\n",
        "These \"stories\" model real conversations between a user and a chatbot. This Markdown-based file is used to define a list of\n",
        "*stories*, and each *story* can have a list of one or more *intents* with (optional) corresponding *slots*, where each *intent*\n",
        "has one or more corresponding actions taken by the chatbot.\n",
        "\n",
        "These actions, in general, can be anything, from simple message replies, to programmable actions that call APIs of other services.\n",
        "*Note:* In this version, supported actions are limited to simple message replies.\n",
        "\n",
        "In a way, it can be seen as a *dialogues dataset*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0oZHwh4K6PG",
        "colab_type": "text"
      },
      "source": [
        "#### format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad2ekquvK8oo",
        "colab_type": "text"
      },
      "source": [
        "Stories file is a markdown file of the following format:\n",
        "\n",
        "```markdown\n",
        "## story_title(not used by algorithm, but useful to work with for humans)\n",
        "* user_action_label{\"1st_slot_present_in_action\": \"slot1_value\", .., \"Nth_slot_present_in_action\": \"slotN_value\"}\n",
        " - system_respective_utterance\n",
        "* another_user_action_of_the_same_format\n",
        "  - another_system_response\n",
        "...\n",
        "\n",
        "## another_story_title\n",
        "...\n",
        "\n",
        "```\n",
        "\n",
        "**See examples below in this tutorial**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nhqxjj_Pedlo",
        "colab_type": "text"
      },
      "source": [
        "### `nlu.md`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zK1TuEvg6KJ",
        "colab_type": "text"
      },
      "source": [
        "`nlu.md` represents an NLU model of your chatbot. It allows you to provide training examples that show how your chatbot should\n",
        "understand user messages, and then train a model through these examples.\n",
        "\n",
        "While DeepPavlov's GO-bot supports JSON-based DSTC-2 format for training data, this Markdown Format introduced by RASA is the easiest one for humans to read and write."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVR4J_UNMAgq",
        "colab_type": "text"
      },
      "source": [
        "#### format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEj0G5ciMBtA",
        "colab_type": "text"
      },
      "source": [
        "NLU file is a markdown file of the following format:\n",
        "\n",
        "```markdown\n",
        "## intent:possible_user_action_label_1\n",
        "- An example of user text that has the possible_user_action_label_1 action label\n",
        "- Another example of user text that has the possible_user_action_label_1 action label\n",
        "...\n",
        "\n",
        "## intent:possible_user_action_label_N\n",
        "- An example of user text that has the (possible_user_action_label_N)[action_label] action label\n",
        "<!-- Slotfilling dataset is provided as an inline markup of user texts -->\n",
        "...\n",
        "\n",
        "```\n",
        "\n",
        "**See examples below in this tutorial**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-wQb3XMfqVJ",
        "colab_type": "text"
      },
      "source": [
        "### `domain.yml`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIlJd3FIg8Hg",
        "colab_type": "text"
      },
      "source": [
        "`domain.yml` helps you to define the universe your chatbot lives in: what user inputs it expects to get, what actions it should be able to predict,\n",
        "how to respond, and what information to store.\n",
        
        "This YML format is relatively simple, and it can be seen as a dictionary of all components of your chatbot, including but not limited to intents,\n",
        "actions, responses, and other things."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5qoE7NnNTEg",
        "colab_type": "text"
      },
      "source": [
        "#### format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gl5QCyVMOpU9",
        "colab_type": "text"
      },
      "source": [
        "Domain file is a YAML file of the following format:\n",
        "\n",
        "```yaml\n",
        "# slots section lists the possible slot names (aka slot types) \n",
        "# that are used in the domain (i.e. relevant for bot's tasks)\n",
        "# currently only type: text is supported\n",
        "slots:\n",
        "  slot1_name:\n",
        "    type: text\n",
        "  ...\n",
        "  slotN_name:\n",
        "    type: text\n",
        "\n",
        "# entities list now follows the slots list 2nd level keys \n",
        "# and is present to support upcoming features. Stay tuned for updates with this!\n",
        "entities:\n",
        "- slot1_name\n",
        "...\n",
        "- slotN_name\n",
        "\n",
        "# intents section lists the intents that can appear in the stories\n",
        "# being kept together they do describe the user-side part of go-bot's experience\n",
        "intents:\n",
        "  - user_action_label\n",
        "  - another_user_action_of_the_same_format\n",
        "  ...\n",
        "\n",
        "# responses section lists the system response templates.\n",
        "# Despite system response' titles being usually informative themselves\n",
        "#   (one could even find them more appropriate when no actual \"Natural Language\" is needed \n",
        "#    (e.g. for buttons actions in bot apps))\n",
        "# It is though extremely useful to be able to serialize the response title to text. \n",
        "# That's what this section content is needed for.\n",
        "responses:\n",
        "  system_utterance_1:\n",
        "    - text: \"The text that system responds with\"\n",
        "  another_system_response:\n",
        "    - text: \"Here some text again\"\n",
        "\n",
        "```\n",
        "\n",
        "**See examples below in this tutorial**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G__SfMVanNGc",
        "colab_type": "text"
      },
      "source": [
        "## Basic Chatbot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAFtnDz4Wbyg",
        "colab_type": "text"
      },
      "source": [
        "Let's build the simplest chatbot possible.\n",
        "This chatbot will be capable of processing three intents: *greeting*, *goodbye*, and *thanks*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BElx8chGte5v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DP_MIN_DEMO_DIR = \"dp_minimal_demo_dir\"  # we will work in this folder"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ypZ3rr1ta44",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "98ff73df-347f-42ca-8645-5e1f0424d59d"
      },
      "source": [
        "import os\n",
        "\n",
        "%cd /content\n",
        "os.makedirs(DP_MIN_DEMO_DIR, exist_ok=True)\n",
        "%cd {DP_MIN_DEMO_DIR}"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/dp_minimal_demo_dir\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwJPzxgqWrgf",
        "colab_type": "text"
      },
      "source": [
        "`stories.md` here is pretty straightforward. In it, you define 3 stories, each having its own intent and reply (utterance).\n",
        "Take into account the fact that you can combine all of these intents under one story, or add two intents to one stories, and third to another one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsVgqFHxnUFq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1d07a7d2-2256-4599-ed52-08ffb591a5e5"
      },
      "source": [
        "%%writefile stories.md\n",
        "\n",
        "## greet\n",
        "* greet\n",
        "  - utter_greet\n",
        "\n",
        "## thank\n",
        "* thank\n",
        "  - utter_noworries\n",
        "\n",
        "## goodbye\n",
        "* bye\n",
        "  - utter_bye"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing stories.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oz_qOBjaW2v7",
        "colab_type": "text"
      },
      "source": [
        "`nlu.md` has an NLU training data that enables DeepPavlov to recognize user phrases as belonging to one the pre-defined intents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk1GzeqAuK59",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7168bd9f-7e90-4eba-b834-a3c4403b91ba"
      },
      "source": [
        "%%writefile nlu.md\n",
        "\n",
        "## intent:greet\n",
        "- Hi\n",
        "- Hey\n",
        "- Hi bot\n",
        "- Hey bot\n",
        "- Hello\n",
        "- Good morning\n",
        "- hi again\n",
        "- hi folks\n",
        "\n",
        "## intent:bye\n",
        "- goodbye\n",
        "- goodnight\n",
        "- good bye\n",
        "- good night\n",
        "- see ya\n",
        "- toodle-oo\n",
        "- bye bye\n",
        "- gotta go\n",
        "- farewell\n",
        "\n",
        "## intent:thank\n",
        "- Thanks\n",
        "- Thank you\n",
        "- Thank you so much\n",
        "- Thanks bot\n",
        "- Thanks for that\n",
        "- cheers\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing nlu.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gt8b1LWTW8mM",
        "colab_type": "text"
      },
      "source": [
        "`domain.yml` lists the list of: \n",
        "* possible user action intents \n",
        "* possible system response actions\n",
        "\n",
        "*Note:* Entities and slots are omitted in this example. See the more sophisticated example below to see how they are defined in the `domain.yml`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srHE4tBhvMW4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b7f50f8f-ae39-43ce-96e1-2bedf56b3b8f"
      },
      "source": [
        "%%writefile domain.yml\n",
        "\n",
        "intents:\n",
        "  - greet\n",
        "  - bye\n",
        "  - thank\n",
        "\n",
        "responses:\n",
        "  utter_noworries:\n",
        "  - text: No worries!\n",
        "  utter_greet:\n",
        "  - text: Hi\n",
        "  utter_bye:\n",
        "  - text: Bye!"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing domain.yml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75BDcU4yXY1g",
        "colab_type": "text"
      },
      "source": [
        "The next step is to install the `deeppavlov` library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zcp4-WpCzHaH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b45380ea-bcf1-45a1-e883-677873590e95"
      },
      "source": [
        "!pip install git+https://github.com/deepmipt/DeepPavlov.git@feature/gobot-md-yaml-config\n",
        "!python -m deeppavlov install gobot_simple_dstc2"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/deepmipt/DeepPavlov.git@feature/gobot-md-yaml-config\n",
            "  Cloning https://github.com/deepmipt/DeepPavlov.git (to revision feature/gobot-md-yaml-config) to /tmp/pip-req-build-ht9t75ir\n",
            "  Running command git clone -q https://github.com/deepmipt/DeepPavlov.git /tmp/pip-req-build-ht9t75ir\n",
            "  Running command git checkout -b feature/gobot-md-yaml-config --track origin/feature/gobot-md-yaml-config\n",
            "  Switched to a new branch 'feature/gobot-md-yaml-config'\n",
            "  Branch 'feature/gobot-md-yaml-config' set up to track remote branch 'feature/gobot-md-yaml-config' from 'origin'.\n",
            "Collecting aio-pika==6.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/07/196a4115cbef31fa0c3dabdea146f02dffe5e49998341d20dbe2278953bc/aio_pika-6.4.1-py3-none-any.whl (40kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 3.7MB/s \n",
            "\u001b[?25hCollecting Cython==0.29.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/d1/4d3f8a7a920e805488a966cc6ab55c978a712240f584445d703c08b9f405/Cython-0.29.14-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 12.1MB/s \n",
            "\u001b[?25hCollecting fastapi==0.47.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/a7/4804d7abf8a1544d079d50650af872387154ebdac5bd07d54b2e60e2b334/fastapi-0.47.1-py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.6/dist-packages (from deeppavlov==0.11.0) (2.10.0)\n",
            "Collecting nltk==3.4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 41.1MB/s \n",
            "\u001b[?25hCollecting numpy==1.18.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/e6/45f71bd24f4e37629e9db5fb75caab919507deae6a5a257f9e4685a5f931/numpy-1.18.0-cp36-cp36m-manylinux1_x86_64.whl (20.1MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1MB 160kB/s \n",
            "\u001b[?25hCollecting overrides==2.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/98/2430afd204c48ac0a529d439d7e22df8fa603c668d03456b5947cb59ec36/overrides-2.7.0.tar.gz\n",
            "Collecting pandas==0.25.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/3f/f6a428599e0d4497e1595030965b5ba455fd8ade6e977e3c819973c4b41d/pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4MB 55.8MB/s \n",
            "\u001b[?25hCollecting pytz==2019.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/73/fe30c2daaaa0713420d0382b16fbb761409f532c56bdcc514bf7b6262bb6/pytz-2019.1-py2.py3-none-any.whl (510kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 48.5MB/s \n",
            "\u001b[?25hCollecting pydantic==1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/24/e78cf017628e7eaed20cb040999b1ecc69f872da53dfd0d9aed40c0fa5f1/pydantic-1.3-cp36-cp36m-manylinux2010_x86_64.whl (7.3MB)\n",
            "\u001b[K     |████████████████████████████████| 7.3MB 17.1MB/s \n",
            "\u001b[?25hCollecting pymorphy2==0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.1MB/s \n",
            "\u001b[?25hCollecting pymorphy2-dicts-ru\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/9b/358faaff410f65a4ad159275e897b5956dcb20576c5b8e764b971c1634d7/pymorphy2_dicts_ru-2.4.404381.4453942-py2.py3-none-any.whl (8.0MB)\n",
            "\u001b[K     |████████████████████████████████| 8.0MB 23.7MB/s \n",
            "\u001b[?25hCollecting pyopenssl==19.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/de/f8342b68fa9e981d348039954657bdf681b2ab93de27443be51865ffa310/pyOpenSSL-19.1.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.9MB/s \n",
            "\u001b[?25hCollecting pytelegrambotapi==3.6.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/ab/99c606f69fcda57e35788b913dd34c9d9acb48dd26349141b3855dcf6351/pyTelegramBotAPI-3.6.7.tar.gz (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 12.0MB/s \n",
            "\u001b[?25hCollecting requests==2.22.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.8MB/s \n",
            "\u001b[?25hCollecting ruamel.yaml==0.15.100\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/9f/83bb34eaf84032b0b54fcc4a6aff1858572d279d65a301c7ae875f523df5/ruamel.yaml-0.15.100-cp36-cp36m-manylinux1_x86_64.whl (656kB)\n",
            "\u001b[K     |████████████████████████████████| 665kB 43.7MB/s \n",
            "\u001b[?25hCollecting rusenttokenize==0.0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/25/4c/a2f00be5def774a3df2e5387145f1cb54e324607ec4a7e23f573645946e7/rusenttokenize-0.0.5-py3-none-any.whl\n",
            "Collecting scikit-learn==0.21.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/04/49633f490f726da6e454fddc8e938bbb5bfed2001681118d3814c219b723/scikit_learn-0.21.2-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 35.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from deeppavlov==0.11.0) (1.4.1)\n",
            "Requirement already satisfied: tqdm==4.41.1 in /usr/local/lib/python3.6/dist-packages (from deeppavlov==0.11.0) (4.41.1)\n",
            "Requirement already satisfied: click==7.1.2 in /usr/local/lib/python3.6/dist-packages (from deeppavlov==0.11.0) (7.1.2)\n",
            "Collecting uvicorn==0.11.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/24/11f4b4bf3963ead6de570feeae49eeced02f6768cf1f68e16f4b16d3b0aa/uvicorn-0.11.1-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.1MB/s \n",
            "\u001b[?25hCollecting sacremoses==0.0.35\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
            "\u001b[K     |████████████████████████████████| 860kB 51.0MB/s \n",
            "\u001b[?25hCollecting aiormq<4,>=3.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/6b/c6/4a9f8f22eef268289e9af5da6a620d837c700b333eae01132bfe48fe7dc9/aiormq-3.2.3-py3-none-any.whl\n",
            "Collecting yarl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/9a/2365a077c21c3d711b2367199a81edbe3f362712a05f6437647ca770eab1/yarl-1.5.0-cp36-cp36m-manylinux1_x86_64.whl (257kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 61.0MB/s \n",
            "\u001b[?25hCollecting starlette<=0.12.9,>=0.12.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/95/2220fe5bf287e693a6430d8ee36c681b0157035b7249ec08f8fb36319d16/starlette-0.12.9.tar.gz (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py==2.10.0->deeppavlov==0.11.0) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.3->deeppavlov==0.11.0) (2.8.1)\n",
            "Requirement already satisfied: dataclasses>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from pydantic==1.3->deeppavlov==0.11.0) (0.7)\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 22.4MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2==0.8->deeppavlov==0.11.0) (0.6.2)\n",
            "Collecting cryptography>=2.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/91/84a29d6a27fd6dfc21f475704c4d2053d58ed7a4033c2b0ce1b4ca4d03d9/cryptography-3.0-cp35-abi3-manylinux2010_x86_64.whl (2.7MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 48.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov==0.11.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov==0.11.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov==0.11.0) (2020.6.20)\n",
            "Collecting idna<2.9,>=2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21.2->deeppavlov==0.11.0) (0.16.0)\n",
            "Collecting uvloop>=0.14.0; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"pypy\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/48/586225bbb02d3bdca475b17e4be5ce5b3f09da2d6979f359916c1592a687/uvloop-0.14.0-cp36-cp36m-manylinux2010_x86_64.whl (3.9MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 49.7MB/s \n",
            "\u001b[?25hCollecting h11<0.10,>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/fd/3dad730b0f95e78aeeb742f96fa7bbecbdd56a58e405d3da440d5bfb90c6/h11-0.9.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.6MB/s \n",
            "\u001b[?25hCollecting httptools==0.0.13; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"pypy\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/03/215969db11abe8741e9c266a4cbe803a372bd86dd35fa0084c4df6d4bd00/httptools-0.0.13.tar.gz (104kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 66.9MB/s \n",
            "\u001b[?25hCollecting websockets==8.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/d9/856af84843912e2853b1b6e898ac8b802989fcf9ecf8e8445a1da263bf3b/websockets-8.1-cp36-cp36m-manylinux2010_x86_64.whl (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.0MB/s \n",
            "\u001b[?25hCollecting pamqp==2.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/56/afa06143361e640c9159d828dadc95fc9195c52c95b4a97d136617b0166d/pamqp-2.3.0-py2.py3-none-any.whl\n",
            "Collecting multidict>=4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/95/f50352b5366e7d579e8b99631680a9e32e1b22adfa1629a8f23b1d22d5e2/multidict-4.7.6-cp36-cp36m-manylinux1_x86_64.whl (148kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 64.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.6/dist-packages (from yarl->aio-pika==6.4.1->deeppavlov==0.11.0) (3.7.4.2)\n",
            "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.8->pyopenssl==19.1.0->deeppavlov==0.11.0) (1.14.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.8->pyopenssl==19.1.0->deeppavlov==0.11.0) (2.20)\n",
            "Building wheels for collected packages: deeppavlov, nltk, overrides, pytelegrambotapi, sacremoses, starlette, httptools\n",
            "  Building wheel for deeppavlov (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deeppavlov: filename=deeppavlov-0.11.0-cp36-none-any.whl size=868656 sha256=9a9550334b945f2e26cef30bd8bc428c42a467135d976916f65898e7488d54d9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-feplo0oh/wheels/d1/14/83/51a15d3d0cc9bf87e735c1daddf375ad226313aa14d8cd04d9\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-cp36-none-any.whl size=1449906 sha256=faaafccc1eee6610a06d7772c4269d6c5c4fa18ef5d8fdfe3dc3ecb157b73762\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-2.7.0-cp36-none-any.whl size=5600 sha256=f8e46cd7a21a94ddf1d41f2c7a09524049e03e673afd98d671e5f1e851e5895e\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/7c/ef/80508418b67d87371c5b3de49e03eb22ee7c1d19affb5099f8\n",
            "  Building wheel for pytelegrambotapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytelegrambotapi: filename=pyTelegramBotAPI-3.6.7-cp36-none-any.whl size=47178 sha256=a9a67520c5763aa65d48ee6953456f15ce986b98236d3d0bb32be02d4955d3f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/40/18/8a34153f95ef0dc19e3954898e5a5079244b76a8afdd7d0ec5\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=149a14b74a89a516e0cb0e2555b7754fc47d0b527647d5830350ee8f2802b6a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
            "  Building wheel for starlette (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for starlette: filename=starlette-0.12.9-cp36-none-any.whl size=57245 sha256=95980c5401330cf5c689f05cee9ce7c4c8e5ee3c81e1a95164950370b67a58fe\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/51/5b/3828d52e185cafad941c4291b6f70894d0794be28c70addae5\n",
            "  Building wheel for httptools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for httptools: filename=httptools-0.0.13-cp36-cp36m-linux_x86_64.whl size=212537 sha256=bb171a2a60de36faeb1af66c5ab50c99f2e9d914c64f18625f9931877f897286\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/3e/2e/013f99b42efc25cf3589730cf380738e46b1e5edaf2f78d525\n",
            "Successfully built deeppavlov nltk overrides pytelegrambotapi sacremoses starlette httptools\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.0.0; python_version >= \"3.0\", but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: idna, multidict, yarl, pamqp, aiormq, aio-pika, Cython, starlette, pydantic, fastapi, nltk, numpy, overrides, pytz, pandas, pymorphy2-dicts, dawg-python, pymorphy2, pymorphy2-dicts-ru, cryptography, pyopenssl, requests, pytelegrambotapi, ruamel.yaml, rusenttokenize, scikit-learn, uvloop, h11, httptools, websockets, uvicorn, sacremoses, deeppavlov\n",
            "  Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Found existing installation: Cython 0.29.21\n",
            "    Uninstalling Cython-0.29.21:\n",
            "      Successfully uninstalled Cython-0.29.21\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "  Found existing installation: pytz 2018.9\n",
            "    Uninstalling pytz-2018.9:\n",
            "      Successfully uninstalled pytz-2018.9\n",
            "  Found existing installation: pandas 1.0.5\n",
            "    Uninstalling pandas-1.0.5:\n",
            "      Successfully uninstalled pandas-1.0.5\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed Cython-0.29.14 aio-pika-6.4.1 aiormq-3.2.3 cryptography-3.0 dawg-python-0.7.2 deeppavlov-0.11.0 fastapi-0.47.1 h11-0.9.0 httptools-0.0.13 idna-2.8 multidict-4.7.6 nltk-3.4.5 numpy-1.18.0 overrides-2.7.0 pamqp-2.3.0 pandas-0.25.3 pydantic-1.3 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985 pymorphy2-dicts-ru-2.4.404381.4453942 pyopenssl-19.1.0 pytelegrambotapi-3.6.7 pytz-2019.1 requests-2.22.0 ruamel.yaml-0.15.100 rusenttokenize-0.0.5 sacremoses-0.0.35 scikit-learn-0.21.2 starlette-0.12.9 uvicorn-0.11.1 uvloop-0.14.0 websockets-8.1 yarl-1.5.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "idna",
                  "numpy",
                  "pandas",
                  "pytz",
                  "requests"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:36:33.761 INFO in 'deeppavlov.core.common.file'['file'] at line 32: Interpreting 'gobot_simple_dstc2' as '/usr/local/lib/python3.6/dist-packages/deeppavlov/configs/go_bot/gobot_simple_dstc2.json'\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (49.1.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.22.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.7.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "Collecting spacy==2.2.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/13/80ad28ef7a16e2a86d16d73e28588be5f1085afd3e85e4b9b912bd700e8a/spacy-2.2.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4MB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3) (49.1.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3) (3.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3) (1.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3) (0.7.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3) (2.22.0)\n",
            "Collecting thinc<7.4.0,>=7.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/59/6bb553bc9a5f072d3cd479fc939fea0f6f682892f1f5cff98de5c9b615bb/thinc-7.3.1-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 56.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3) (1.18.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3) (2.0.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy==2.2.3) (1.7.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3) (2.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3) (2020.6.20)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.4.0,>=7.3.0->spacy==2.2.3) (4.41.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy==2.2.3) (3.1.0)\n",
            "Installing collected packages: thinc, spacy\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed spacy-2.2.3 thinc-7.3.1\n",
            "Collecting tensorflow==1.15.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/d9/fd234c7bf68638423fb8e7f44af7fcfce3bcaf416b51e6d902391e47ec43/tensorflow-1.15.2-cp36-cp36m-manylinux2010_x86_64.whl (110.5MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5MB 36kB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.12.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (3.12.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.30.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 53.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.9.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.8.1)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 52.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.34.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.1.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.0.8)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.18.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.2) (49.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.2) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=70a99ec04dc3ebce098bf1aec4250f7274f095aeba7f8aae75dee0dddf80e399\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, gast, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.2.2\n",
            "    Uninstalling tensorboard-2.2.2:\n",
            "      Successfully uninstalled tensorboard-2.2.2\n",
            "  Found existing installation: tensorflow 2.2.0\n",
            "    Uninstalling tensorflow-2.2.0:\n",
            "      Successfully uninstalled tensorflow-2.2.0\n",
            "Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-1.15.2 tensorflow-estimator-1.15.1\n",
            "Collecting gensim==3.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/dd/112bd4258cee11e0baaaba064060eb156475a42362e59e3ff28e7ca2d29d/gensim-3.8.1-cp36-cp36m-manylinux1_x86_64.whl (24.2MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2MB 132kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim==3.8.1) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.6/dist-packages (from gensim==3.8.1) (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim==3.8.1) (1.18.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim==3.8.1) (1.15.0)\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim==3.8.1) (2.49.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim==3.8.1) (1.14.24)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim==3.8.1) (2.22.0)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.24 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim==3.8.1) (1.17.24)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim==3.8.1) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim==3.8.1) (0.3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim==3.8.1) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim==3.8.1) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim==3.8.1) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim==3.8.1) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.24->boto3->smart-open>=1.8.1->gensim==3.8.1) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.24->boto3->smart-open>=1.8.1->gensim==3.8.1) (0.15.2)\n",
            "Installing collected packages: gensim\n",
            "  Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-3.8.1\n",
            "Collecting rapidfuzz==0.7.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/4e/66d1ad1ad9f7f1e82c68632a6683c2408cc0e134cebf1a67572370379557/rapidfuzz-0.7.6-cp36-cp36m-manylinux2010_x86_64.whl (689kB)\n",
            "\u001b[K     |████████████████████████████████| 696kB 4.6MB/s \n",
            "\u001b[?25hInstalling collected packages: rapidfuzz\n",
            "Successfully installed rapidfuzz-0.7.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGxtOE-fXiUN",
        "colab_type": "text"
      },
      "source": [
        "Define the path to our DSL-based configuration files above (the folder we are in right now) and the folder used to store the trained bot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcC7aDfk6iiM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from deeppavlov import configs\n",
        "from deeppavlov.core.common.file import read_json\n",
        "\n",
        "\n",
        "gobot_config = read_json(configs.go_bot.gobot_md_yaml_minimal)\n",
        "\n",
        "gobot_config['metadata']['variables']['DATA_PATH'] = '.'\n",
        "gobot_config['metadata']['variables']['MODEL_PATH'] = '.'\n",
        "\n",
        "!echo \"{}\" > dstc2-actions2slots.json  # a hack that will be redundant in future versions. It is an empty json file in the data folder."
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOenbeUvXwW-",
        "colab_type": "text"
      },
      "source": [
        "Since our data is basically the mock tutorial data we will use the same subsamples for all of train, test and valid subsamples. \n",
        "\n",
        "However, for a real system you should use different train, test, and valid sample NLU.md files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reCVX2Mz7W8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp stories.md stories-trn.md\n",
        "!cp stories.md stories-tst.md \n",
        "!cp stories.md stories-val.md "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjPL3dqzYj3B",
        "colab_type": "text"
      },
      "source": [
        "The next step is to train the bot:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS6hIi9m7Sev",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "27c5e956-09f1-4944-c841-de2e48f0e1e2"
      },
      "source": [
        "from deeppavlov import train_model\n",
        "\n",
        "train_model(gobot_config, download=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:37:57.180 INFO in 'deeppavlov.core.data.utils'['utils'] at line 94: Downloading from http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt to /root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt\n",
            "347MB [00:32, 10.5MB/s]\n",
            "2020-07-29 14:38:30.843 INFO in 'deeppavlov.download'['download'] at line 132: Skipped http://files.deeppavlov.ai/datasets/gobot_md_yaml_minimal.tar.gz download because of matching hashes\n",
            "2020-07-29 14:38:30.863 INFO in 'deeppavlov.dataset_readers.md_yaml_dialogs_reader'['md_yaml_dialogs_reader'] at line 123: INSIDE MLU_MD_DialogsDatasetReader._read_domain_knowledge(): reading domain knowledge from /content/dp_minimal_demo_dir/domain.yml\n",
            "2020-07-29 14:38:30.867 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmpcurn6nz6]\n",
            "2020-07-29 14:38:30.869 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmphq61lzvb]\n",
            "2020-07-29 14:38:30.871 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmp4sp7ebop]\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data] Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "2020-07-29 14:38:32.530 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /content/dp_minimal_demo_dir/word.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:38:34.266 INFO in 'deeppavlov.dataset_readers.md_yaml_dialogs_reader'['md_yaml_dialogs_reader'] at line 123: INSIDE MLU_MD_DialogsDatasetReader._read_domain_knowledge(): reading domain knowledge from /content/dp_minimal_demo_dir/domain.yml\n",
            "2020-07-29 14:38:34.270 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmpdxtbv00d]\n",
            "2020-07-29 14:38:34.272 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmpxhizv1vt]\n",
            "2020-07-29 14:38:34.276 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmpdswqgy4w]\n",
            "2020-07-29 14:38:34.375 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/common/registry.py:40: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:194: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/go_bot/policy/policy_network.py:250: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/go_bot/policy/policy_network.py:265: The name tf.nn.rnn_cell.LSTMStateTuple is deprecated. Please use tf.compat.v1.nn.rnn_cell.LSTMStateTuple instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/go_bot/policy/policy_network.py:276: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/go_bot/policy/policy_network.py:285: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/go_bot/policy/policy_network.py:292: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/go_bot/policy/policy_network.py:246: The name tf.losses.get_regularization_loss is deprecated. Please use tf.compat.v1.losses.get_regularization_loss instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:122: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:127: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:127: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py:2825: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/go_bot/policy/policy_network.py:79: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/go_bot/policy/policy_network.py:335: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:39:10.983 INFO in 'deeppavlov.models.go_bot.policy.policy_network'['policy_network'] at line 89: INSIDE PolicyNetwork init(). Initializing PolicyNetwork from scratch.\n",
            "2020-07-29 14:39:11.39 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 198: Initial best per_item_action_accuracy of 0.6667\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 0.6667}, \"time_spent\": \"0:00:01\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 10}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:39:11.326 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best per_item_action_accuracy of 1.0\n",
            "2020-07-29 14:39:11.327 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 14:39:11.329 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/dp_minimal_demo_dir/model/policy]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:01\", \"epochs_done\": 14, \"batches_seen\": 15, \"train_examples_seen\": 45, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.5423726851741473}}\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:77: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "{\"valid\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:01\", \"epochs_done\": 14, \"batches_seen\": 15, \"train_examples_seen\": 45, \"impatience\": 0, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:01\", \"epochs_done\": 29, \"batches_seen\": 30, \"train_examples_seen\": 90, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.0295912300546964}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:39:11.534 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 1.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:01\", \"epochs_done\": 29, \"batches_seen\": 30, \"train_examples_seen\": 90, \"impatience\": 1, \"patience_limit\": 10}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:39:11.653 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 1.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:01\", \"epochs_done\": 44, \"batches_seen\": 45, \"train_examples_seen\": 135, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.023871572315692903}}\n",
            "{\"valid\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:01\", \"epochs_done\": 44, \"batches_seen\": 45, \"train_examples_seen\": 135, \"impatience\": 2, \"patience_limit\": 10}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:39:11.763 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 1.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:01\", \"epochs_done\": 59, \"batches_seen\": 60, \"train_examples_seen\": 180, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.023093622798720997}}\n",
            "{\"valid\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:01\", \"epochs_done\": 59, \"batches_seen\": 60, \"train_examples_seen\": 180, \"impatience\": 3, \"patience_limit\": 10}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:39:11.873 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 1.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:01\", \"epochs_done\": 74, \"batches_seen\": 75, \"train_examples_seen\": 225, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.021588064233462014}}\n",
            "{\"valid\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:01\", \"epochs_done\": 74, \"batches_seen\": 75, \"train_examples_seen\": 225, \"impatience\": 4, \"patience_limit\": 10}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:39:11.982 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 1.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:01\", \"epochs_done\": 89, \"batches_seen\": 90, \"train_examples_seen\": 270, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.019758499786257745}}\n",
            "{\"valid\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:01\", \"epochs_done\": 89, \"batches_seen\": 90, \"train_examples_seen\": 270, \"impatience\": 5, \"patience_limit\": 10}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:39:12.95 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 1.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:02\", \"epochs_done\": 104, \"batches_seen\": 105, \"train_examples_seen\": 315, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.017879931380351384}}\n",
            "{\"valid\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:02\", \"epochs_done\": 104, \"batches_seen\": 105, \"train_examples_seen\": 315, \"impatience\": 6, \"patience_limit\": 10}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:39:12.205 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 1.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:02\", \"epochs_done\": 119, \"batches_seen\": 120, \"train_examples_seen\": 360, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.01610003933310509}}\n",
            "{\"valid\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:02\", \"epochs_done\": 119, \"batches_seen\": 120, \"train_examples_seen\": 360, \"impatience\": 7, \"patience_limit\": 10}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:39:12.316 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 1.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:02\", \"epochs_done\": 134, \"batches_seen\": 135, \"train_examples_seen\": 405, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.014478032290935517}}\n",
            "{\"valid\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:02\", \"epochs_done\": 134, \"batches_seen\": 135, \"train_examples_seen\": 405, \"impatience\": 8, \"patience_limit\": 10}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:39:12.428 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 1.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:02\", \"epochs_done\": 149, \"batches_seen\": 150, \"train_examples_seen\": 450, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.01302755419164896}}\n",
            "{\"valid\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:02\", \"epochs_done\": 149, \"batches_seen\": 150, \"train_examples_seen\": 450, \"impatience\": 9, \"patience_limit\": 10}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:39:12.543 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 1.0\n",
            "2020-07-29 14:39:12.544 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 307: Ran out of patience\n",
            "2020-07-29 14:39:12.613 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/dp_minimal_demo_dir/word.dict]\n",
            "2020-07-29 14:39:12.614 INFO in 'deeppavlov.dataset_readers.md_yaml_dialogs_reader'['md_yaml_dialogs_reader'] at line 123: INSIDE MLU_MD_DialogsDatasetReader._read_domain_knowledge(): reading domain knowledge from /content/dp_minimal_demo_dir/domain.yml\n",
            "2020-07-29 14:39:12.619 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmp8ou_pgzg]\n",
            "2020-07-29 14:39:12.621 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmp49lkecgq]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:02\", \"epochs_done\": 164, \"batches_seen\": 165, \"train_examples_seen\": 495, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.01174297413478295}}\n",
            "{\"valid\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:02\", \"epochs_done\": 164, \"batches_seen\": 165, \"train_examples_seen\": 495, \"impatience\": 10, \"patience_limit\": 10}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:39:12.625 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmptq0mhe5x]\n",
            "2020-07-29 14:39:12.628 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n",
            "2020-07-29 14:39:46.99 INFO in 'deeppavlov.models.go_bot.policy.policy_network'['policy_network'] at line 86: INSIDE PolicyNetwork init(). Initializing PolicyNetwork from checkpoint.\n",
            "2020-07-29 14:39:46.104 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/dp_minimal_demo_dir/model/policy]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/dp_minimal_demo_dir/model/policy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:39:46.264 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/dp_minimal_demo_dir/word.dict]\n",
            "2020-07-29 14:39:46.265 INFO in 'deeppavlov.dataset_readers.md_yaml_dialogs_reader'['md_yaml_dialogs_reader'] at line 123: INSIDE MLU_MD_DialogsDatasetReader._read_domain_knowledge(): reading domain knowledge from /content/dp_minimal_demo_dir/domain.yml\n",
            "2020-07-29 14:39:46.271 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmpmkf5ffbh]\n",
            "2020-07-29 14:39:46.273 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmp9h0rcngd]\n",
            "2020-07-29 14:39:46.275 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmpwzmh0clp]\n",
            "2020-07-29 14:39:46.277 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:01\"}}\n",
            "{\"test\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:01\"}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:40:20.543 INFO in 'deeppavlov.models.go_bot.policy.policy_network'['policy_network'] at line 86: INSIDE PolicyNetwork init(). Initializing PolicyNetwork from checkpoint.\n",
            "2020-07-29 14:40:20.547 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/dp_minimal_demo_dir/model/policy]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/dp_minimal_demo_dir/model/policy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Chainer[<deeppavlov.models.go_bot.wrapper.DialogComponentWrapper at 0x7f092e14e6a0>,\n",
              "        <deeppavlov.models.go_bot.go_bot.GoalOrientedBot at 0x7f089943bba8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tenEY1QVYmlg",
        "colab_type": "text"
      },
      "source": [
        "Finally, it's time to build our bot and experiment with it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmK7I_06xXcH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "0c14d21c-7286-429a-da02-043530a5a19a"
      },
      "source": [
        "from deeppavlov import build_model\n",
        "bot = build_model(gobot_config)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:40:20.600 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/dp_minimal_demo_dir/word.dict]\n",
            "2020-07-29 14:40:20.603 INFO in 'deeppavlov.dataset_readers.md_yaml_dialogs_reader'['md_yaml_dialogs_reader'] at line 123: INSIDE MLU_MD_DialogsDatasetReader._read_domain_knowledge(): reading domain knowledge from /content/dp_minimal_demo_dir/domain.yml\n",
            "2020-07-29 14:40:20.607 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmpptiu0uf8]\n",
            "2020-07-29 14:40:20.609 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmpvnyl95qn]\n",
            "2020-07-29 14:40:20.611 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmp7jidr5bi]\n",
            "2020-07-29 14:40:20.613 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n",
            "2020-07-29 14:40:54.910 INFO in 'deeppavlov.models.go_bot.policy.policy_network'['policy_network'] at line 86: INSIDE PolicyNetwork init(). Initializing PolicyNetwork from checkpoint.\n",
            "2020-07-29 14:40:54.915 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/dp_minimal_demo_dir/model/policy]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/dp_minimal_demo_dir/model/policy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2hpK1G0x0gu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "756e5dc0-79ae-4cc3-cf7c-5e2b4a4a2140"
      },
      "source": [
        "bot.reset()\n",
        "\n",
        "bot([\"start\"])\n",
        "bot([\"Hi\"])[0][0].actions_tuple"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('utter_greet',)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbUm-l73Yvry",
        "colab_type": "text"
      },
      "source": [
        "Our bot answers with \"greeting\" to our \"greeting\". What will it respond to some grateful message?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKQ86ESXx9GV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4219ed46-e7b1-4375-87e2-36840b05d529"
      },
      "source": [
        "bot.reset()\n",
        "bot([\"start\"])\n",
        "\n",
        "bot([\"Thanks!\"])[0][0].actions_tuple"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('utter_noworries',)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvkEelaEY3kb",
        "colab_type": "text"
      },
      "source": [
        "Ok, \"no woories\" is an expected response. Let's check if the \"goodbye\" user message is processed with the corresponding reply:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aM9xCLMs5Ke5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bot.reset()\n",
        "bot([\"start\"])\n",
        "\n",
        "bot_response_actions = bot([\"bye\"])[0][0].actions_tuple"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhqKmwbO6K1v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "45ac0152-8212-45c6-ec60-fcc047c06c81"
      },
      "source": [
        "import yaml\n",
        "\n",
        "system_utter2text = yaml.load(open(\"domain.yml\"))[\"responses\"]\n",
        "system_utter2text[bot_response_actions[0]][0][\"text\"]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Bye!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJUFlCjinRsP",
        "colab_type": "text"
      },
      "source": [
        "## More Realistic Demo: Using the DSTSC Schema-Guided Dialogue Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Yf5iQC1nh7d",
        "colab_type": "text"
      },
      "source": [
        "Now let's take the [Schema](asdf) dataset.\n",
        "We naively converted most of *Restaurants 1* dialogues from Schema to the md+yml format to keep things simple. \n",
        "\n",
        "These are the annotated dialogs on the restaurant tables booking domain.\n",
        "We will not involve the DB usage in our example and the bot should just learn to respond with relevant actions to user's utterances.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilk5KxbBi98e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DP_BIG_DEMO_DIR = \"dp_big_demo_dir\"  # we'll work in this directory"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqCEXGyEjDrQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "35255387-c8aa-465b-a412-3056c6d2a9eb"
      },
      "source": [
        "import os\n",
        "\n",
        "%cd /content\n",
        "os.makedirs(DP_BIG_DEMO_DIR, exist_ok=True)\n",
        "%cd {DP_BIG_DEMO_DIR}"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/dp_big_demo_dir\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XcO1oe7nw7G",
        "colab_type": "text"
      },
      "source": [
        "download the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSgoo2CSk0Ku",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "8dadc097-3102-44d0-d0a7-313248fbc4bc"
      },
      "source": [
        "# let's get the mentioned converted Schema-dataset subset\n",
        "!wget http://files.deeppavlov.ai/datasets/schema_resto_md_yaml.tar.gz\n",
        "!tar -zxf schema_resto_md_yaml.tar.gz "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-29 14:40:56--  http://files.deeppavlov.ai/datasets/schema_resto_md_yaml.tar.gz\n",
            "Resolving files.deeppavlov.ai (files.deeppavlov.ai)... 93.175.29.74\n",
            "Connecting to files.deeppavlov.ai (files.deeppavlov.ai)|93.175.29.74|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 98725 (96K) [application/octet-stream]\n",
            "Saving to: ‘schema_resto_md_yaml.tar.gz’\n",
            "\n",
            "\r          schema_re   0%[                    ]       0  --.-KB/s               \r         schema_res  49%[========>           ]  47.81K   134KB/s               \rschema_resto_md_yam 100%[===================>]  96.41K   270KB/s    in 0.4s    \n",
            "\n",
            "2020-07-29 14:40:57 (270 KB/s) - ‘schema_resto_md_yaml.tar.gz’ saved [98725/98725]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kf2Tm6RbZwOx",
        "colab_type": "text"
      },
      "source": [
        "First of all let's train the NER model that will be used by bot. No .md or .yml configs illustrated here, but the trained model is inevitable part of the go-bot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX9yLwjoltDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from deeppavlov import configs, train_model\n",
        "from deeppavlov.core.common.file import read_json\n",
        "\n",
        "ner_config = read_json(configs.ner.ner_conll2003)\n",
        "ner_config[\"dataset_reader\"] = read_json(configs.ner.ner_few_shot_ru)[\"dataset_reader\"]\n",
        "ner_config[\"dataset_reader\"][\"data_path\"] = \"schema_resto_md_yaml/ner\""
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lAcp-Rxm-IX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "e1428037-3609-414f-d03d-1ada14c41e18"
      },
      "source": [
        "!python -m deeppavlov download ner_conll2003\n",
        "!rm -r /root/.deeppavlov/models/ner_conll2003  # remove cached models if present"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:41:02.348 INFO in 'deeppavlov.core.common.file'['file'] at line 32: Interpreting 'ner_conll2003' as '/usr/local/lib/python3.6/dist-packages/deeppavlov/configs/ner/ner_conll2003.json'\n",
            "2020-07-29 14:41:03.321 INFO in 'deeppavlov.download'['download'] at line 132: Skipped http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt?config=ner_conll2003 download because of matching hashes\n",
            "2020-07-29 14:41:03.669 INFO in 'deeppavlov.core.data.utils'['utils'] at line 94: Downloading from http://files.deeppavlov.ai/deeppavlov_data/ner_conll2003_v5.tar.gz?config=ner_conll2003 to /root/.deeppavlov/ner_conll2003_v5.tar.gz\n",
            "100% 3.12M/3.12M [00:01<00:00, 2.26MB/s]\n",
            "2020-07-29 14:41:05.413 INFO in 'deeppavlov.core.data.utils'['utils'] at line 269: Extracting /root/.deeppavlov/ner_conll2003_v5.tar.gz archive into /root/.deeppavlov/models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXaU3YlNbS2f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "64225265-5f87-4448-c0ab-ce72589756f9"
      },
      "source": [
        "# if rm says that these files are missing that's ok \n",
        "#   (we just deleted the whole folder containing these paths ^__^)\n",
        "# but if they're present we should delete them \n",
        "# cause they're checkpoints of some other model\n",
        "!rm /root/.deeppavlov/models/ner_conll2003/{checkpoint,model_no_pos}*"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/root/.deeppavlov/models/ner_conll2003/checkpoint*': No such file or directory\n",
            "rm: cannot remove '/root/.deeppavlov/models/ner_conll2003/model_no_pos*': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ui1hyjUxbU6g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fffb0f4d-bf84-4f20-edcf-48d86e5a6b72"
      },
      "source": [
        "ner_model = train_model(ner_config)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:41:13.76 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /root/.deeppavlov/models/ner_conll2003/word.dict]\n",
            "2020-07-29 14:41:13.82 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /root/.deeppavlov/models/ner_conll2003/tag.dict]\n",
            "2020-07-29 14:41:13.99 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /root/.deeppavlov/models/ner_conll2003/char.dict]\n",
            "2020-07-29 14:41:13.101 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/ner/network.py:96: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/layers/tf_layers.py:420: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/ner/network.py:211: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/common/check_gpu.py:29: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:41:46.602 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 760: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/layers/tf_layers.py:733: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/layers/tf_layers.py:865: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "seq_dim is deprecated, use seq_axis instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py:507: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "batch_dim is deprecated, use batch_axis instead\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:41:46.685 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 760: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2020-07-29 14:41:48.786 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 971 phrases; correct: 0.\n",
            "\n",
            "precision:  0.00%; recall:  0.00%; FB1:  0.00\n",
            "\n",
            "\tcity: precision:  0.00%; recall:  0.00%; F1:  0.00 307\n",
            "\n",
            "\tcuisine: precision:  0.00%; recall:  0.00%; F1:  0.00 278\n",
            "\n",
            "\tdate: precision:  0.00%; recall:  0.00%; F1:  0.00 25\n",
            "\n",
            "\tprice_range: precision:  0.00%; recall:  0.00%; F1:  0.00 193\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 3\n",
            "\n",
            "\ttime: precision:  0.00%; recall:  0.00%; F1:  0.00 165\n",
            "\n",
            "\n",
            "2020-07-29 14:41:48.790 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 198: Initial best ner_f1 of 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 1.4898}, \"time_spent\": \"0:00:01\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:41:52.15 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 474 tokens with 9 phrases; found: 3 phrases; correct: 0.\n",
            "\n",
            "precision:  0.00%; recall:  0.00%; FB1:  0.00\n",
            "\n",
            "\tcity: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\tcuisine: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\tprice_range: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  0.00%; recall:  0.00%; F1:  0.00 3\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 19.0476}, \"time_spent\": \"0:00:04\", \"epochs_done\": 1, \"batches_seen\": 14, \"train_examples_seen\": 854, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 3.7301978128296986}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:41:52.242 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 3 phrases; correct: 0.\n",
            "\n",
            "precision:  33.33%; recall:  3.12%; FB1:  5.71\n",
            "\n",
            "\tcity: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\tcuisine: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\tdate: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\tprice_range: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  33.33%; recall:  33.33%; F1:  33.33 3\n",
            "\n",
            "\n",
            "2020-07-29 14:41:52.245 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 5.7143\n",
            "2020-07-29 14:41:52.246 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 14:41:52.248 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 5.7143, \"ner_token_f1\": 7.4074}, \"time_spent\": \"0:00:04\", \"epochs_done\": 1, \"batches_seen\": 14, \"train_examples_seen\": 854, \"impatience\": 0, \"patience_limit\": 7}}\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:211: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:41:55.193 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 444 tokens with 10 phrases; found: 2 phrases; correct: 0.\n",
            "\n",
            "precision:  50.00%; recall:  10.00%; FB1:  16.67\n",
            "\n",
            "\tcity: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
            "\n",
            "\tcuisine: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 16.6667, \"ner_token_f1\": 40.0}, \"time_spent\": \"0:00:07\", \"epochs_done\": 2, \"batches_seen\": 28, \"train_examples_seen\": 1708, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 1.1017664354294538}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:41:55.431 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 3 phrases; correct: 0.\n",
            "\n",
            "precision:  100.00%; recall:  9.38%; FB1:  17.14\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  12.50%; F1:  22.22 1\n",
            "\n",
            "\tcuisine: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\tdate: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\tprice_range: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  66.67%; F1:  80.00 2\n",
            "\n",
            "\n",
            "2020-07-29 14:41:55.434 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 17.1429\n",
            "2020-07-29 14:41:55.435 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 14:41:55.436 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 17.1429, \"ner_token_f1\": 14.5455}, \"time_spent\": \"0:00:07\", \"epochs_done\": 2, \"batches_seen\": 28, \"train_examples_seen\": 1708, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:41:58.422 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 441 tokens with 7 phrases; found: 4 phrases; correct: 0.\n",
            "\n",
            "precision:  0.00%; recall:  0.00%; FB1:  0.00\n",
            "\n",
            "\tcity: precision:  0.00%; recall:  0.00%; F1:  0.00 4\n",
            "\n",
            "\tcuisine: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\tprice_range: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 33.3333}, \"time_spent\": \"0:00:10\", \"epochs_done\": 3, \"batches_seen\": 42, \"train_examples_seen\": 2562, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.6893018037080765}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:41:58.658 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 23 phrases; correct: 0.\n",
            "\n",
            "precision:  34.78%; recall:  25.00%; FB1:  29.09\n",
            "\n",
            "\tcity: precision:  38.46%; recall:  62.50%; F1:  47.62 13\n",
            "\n",
            "\tcuisine: precision:  0.00%; recall:  0.00%; F1:  0.00 6\n",
            "\n",
            "\tdate: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\tprice_range: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  75.00%; recall:  100.00%; F1:  85.71 4\n",
            "\n",
            "\n",
            "2020-07-29 14:41:58.662 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 29.0909\n",
            "2020-07-29 14:41:58.662 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 14:41:58.663 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 29.0909, \"ner_token_f1\": 60.9756}, \"time_spent\": \"0:00:11\", \"epochs_done\": 3, \"batches_seen\": 42, \"train_examples_seen\": 2562, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:01.653 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 452 tokens with 7 phrases; found: 10 phrases; correct: 0.\n",
            "\n",
            "precision:  40.00%; recall:  57.14%; FB1:  47.06\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 2\n",
            "\n",
            "\tcuisine: precision:  33.33%; recall:  100.00%; F1:  50.00 3\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  20.00%; recall:  33.33%; F1:  25.00 5\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 47.0588, \"ner_token_f1\": 88.2353}, \"time_spent\": \"0:00:14\", \"epochs_done\": 4, \"batches_seen\": 56, \"train_examples_seen\": 3416, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.37738670661513296}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:01.882 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 38 phrases; correct: 0.\n",
            "\n",
            "precision:  34.21%; recall:  40.62%; FB1:  37.14\n",
            "\n",
            "\tcity: precision:  57.14%; recall:  50.00%; F1:  53.33 7\n",
            "\n",
            "\tcuisine: precision:  22.22%; recall:  46.15%; F1:  30.00 27\n",
            "\n",
            "\tdate: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\tprice_range: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  75.00%; recall:  100.00%; F1:  85.71 4\n",
            "\n",
            "\n",
            "2020-07-29 14:42:01.884 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 37.1429\n",
            "2020-07-29 14:42:01.885 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 14:42:01.887 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 37.1429, \"ner_token_f1\": 73.4694}, \"time_spent\": \"0:00:14\", \"epochs_done\": 4, \"batches_seen\": 56, \"train_examples_seen\": 3416, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:04.788 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 376 tokens with 9 phrases; found: 9 phrases; correct: 0.\n",
            "\n",
            "precision:  88.89%; recall:  88.89%; FB1:  88.89\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 2\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  100.00%; F1:  100.00 2\n",
            "\n",
            "\tdate: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  80.00%; recall:  100.00%; F1:  88.89 5\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 88.8889, \"ner_token_f1\": 92.3077}, \"time_spent\": \"0:00:17\", \"epochs_done\": 5, \"batches_seen\": 70, \"train_examples_seen\": 4270, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.2514684115137373}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:05.40 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 33 phrases; correct: 0.\n",
            "\n",
            "precision:  51.52%; recall:  53.12%; FB1:  52.31\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 8\n",
            "\n",
            "\tcuisine: precision:  28.57%; recall:  46.15%; F1:  35.29 21\n",
            "\n",
            "\tdate: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\tprice_range: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  75.00%; recall:  100.00%; F1:  85.71 4\n",
            "\n",
            "\n",
            "2020-07-29 14:42:05.43 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 52.3077\n",
            "2020-07-29 14:42:05.45 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 14:42:05.48 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 52.3077, \"ner_token_f1\": 80.0}, \"time_spent\": \"0:00:17\", \"epochs_done\": 5, \"batches_seen\": 70, \"train_examples_seen\": 4270, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:08.23 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 439 tokens with 10 phrases; found: 11 phrases; correct: 0.\n",
            "\n",
            "precision:  90.91%; recall:  100.00%; FB1:  95.24\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\ttime: precision:  66.67%; recall:  100.00%; F1:  80.00 3\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 95.2381, \"ner_token_f1\": 96.2963}, \"time_spent\": \"0:00:20\", \"epochs_done\": 6, \"batches_seen\": 84, \"train_examples_seen\": 5124, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.16451828035392932}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:08.256 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 39 phrases; correct: 0.\n",
            "\n",
            "precision:  56.41%; recall:  68.75%; FB1:  61.97\n",
            "\n",
            "\tcity: precision:  87.50%; recall:  87.50%; F1:  87.50 8\n",
            "\n",
            "\tcuisine: precision:  50.00%; recall:  76.92%; F1:  60.61 20\n",
            "\n",
            "\tdate: precision:  0.00%; recall:  0.00%; F1:  0.00 3\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  50.00%; F1:  66.67 2\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
            "\n",
            "\ttime: precision:  60.00%; recall:  100.00%; F1:  75.00 5\n",
            "\n",
            "\n",
            "2020-07-29 14:42:08.261 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 61.9718\n",
            "2020-07-29 14:42:08.262 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 14:42:08.264 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 61.9718, \"ner_token_f1\": 82.3529}, \"time_spent\": \"0:00:20\", \"epochs_done\": 6, \"batches_seen\": 84, \"train_examples_seen\": 5124, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:11.307 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 403 tokens with 2 phrases; found: 2 phrases; correct: 0.\n",
            "\n",
            "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"ner_token_f1\": 100.0}, \"time_spent\": \"0:00:23\", \"epochs_done\": 7, \"batches_seen\": 98, \"train_examples_seen\": 5978, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.16415306819336756}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:11.546 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 38 phrases; correct: 0.\n",
            "\n",
            "precision:  60.53%; recall:  71.88%; FB1:  65.71\n",
            "\n",
            "\tcity: precision:  77.78%; recall:  87.50%; F1:  82.35 9\n",
            "\n",
            "\tcuisine: precision:  45.00%; recall:  69.23%; F1:  54.55 20\n",
            "\n",
            "\tdate: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  75.00%; recall:  100.00%; F1:  85.71 4\n",
            "\n",
            "\n",
            "2020-07-29 14:42:11.549 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 65.7143\n",
            "2020-07-29 14:42:11.551 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 14:42:11.552 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 65.7143, \"ner_token_f1\": 89.1089}, \"time_spent\": \"0:00:24\", \"epochs_done\": 7, \"batches_seen\": 98, \"train_examples_seen\": 5978, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:14.561 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 381 tokens with 9 phrases; found: 9 phrases; correct: 0.\n",
            "\n",
            "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 2\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\trestaurant_name: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 5\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"ner_token_f1\": 100.0}, \"time_spent\": \"0:00:27\", \"epochs_done\": 8, \"batches_seen\": 112, \"train_examples_seen\": 6832, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.12894244066306523}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:14.798 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 37 phrases; correct: 0.\n",
            "\n",
            "precision:  64.86%; recall:  75.00%; FB1:  69.57\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 8\n",
            "\n",
            "\tcuisine: precision:  45.00%; recall:  69.23%; F1:  54.55 20\n",
            "\n",
            "\tdate: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\n",
            "2020-07-29 14:42:14.802 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 69.5652\n",
            "2020-07-29 14:42:14.802 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 14:42:14.803 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 69.5652, \"ner_token_f1\": 89.1089}, \"time_spent\": \"0:00:27\", \"epochs_done\": 8, \"batches_seen\": 112, \"train_examples_seen\": 6832, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:17.859 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 490 tokens with 13 phrases; found: 13 phrases; correct: 0.\n",
            "\n",
            "precision:  92.31%; recall:  92.31%; FB1:  92.31\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\trestaurant_name: precision:  66.67%; recall:  66.67%; F1:  66.67 3\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 5\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 92.3077, \"ner_token_f1\": 98.6301}, \"time_spent\": \"0:00:30\", \"epochs_done\": 9, \"batches_seen\": 126, \"train_examples_seen\": 7686, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.0675757857305663}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:18.95 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 35 phrases; correct: 0.\n",
            "\n",
            "precision:  65.71%; recall:  71.88%; FB1:  68.66\n",
            "\n",
            "\tcity: precision:  87.50%; recall:  87.50%; F1:  87.50 8\n",
            "\n",
            "\tcuisine: precision:  47.06%; recall:  61.54%; F1:  53.33 17\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  80.00%; recall:  100.00%; F1:  88.89 5\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  75.00%; recall:  100.00%; F1:  85.71 4\n",
            "\n",
            "\n",
            "2020-07-29 14:42:18.98 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 69.5652\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 68.6567, \"ner_token_f1\": 86.5979}, \"time_spent\": \"0:00:30\", \"epochs_done\": 9, \"batches_seen\": 126, \"train_examples_seen\": 7686, \"impatience\": 1, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:20.829 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 416 tokens with 8 phrases; found: 8 phrases; correct: 0.\n",
            "\n",
            "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\trestaurant_name: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 2\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"ner_token_f1\": 100.0}, \"time_spent\": \"0:00:33\", \"epochs_done\": 10, \"batches_seen\": 140, \"train_examples_seen\": 8540, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.042590158858469555}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:21.68 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 35 phrases; correct: 0.\n",
            "\n",
            "precision:  74.29%; recall:  81.25%; FB1:  77.61\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 8\n",
            "\n",
            "\tcuisine: precision:  55.56%; recall:  76.92%; F1:  64.52 18\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  75.00%; recall:  100.00%; F1:  85.71 4\n",
            "\n",
            "\n",
            "2020-07-29 14:42:21.72 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 77.6119\n",
            "2020-07-29 14:42:21.73 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 14:42:21.74 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 77.6119, \"ner_token_f1\": 91.0891}, \"time_spent\": \"0:00:33\", \"epochs_done\": 10, \"batches_seen\": 140, \"train_examples_seen\": 8540, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:24.26 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 427 tokens with 11 phrases; found: 11 phrases; correct: 0.\n",
            "\n",
            "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 2\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 2\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"ner_token_f1\": 100.0}, \"time_spent\": \"0:00:36\", \"epochs_done\": 11, \"batches_seen\": 154, \"train_examples_seen\": 9394, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.036051063399229734}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:24.254 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 33 phrases; correct: 0.\n",
            "\n",
            "precision:  81.82%; recall:  84.38%; FB1:  83.08\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 8\n",
            "\n",
            "\tcuisine: precision:  64.71%; recall:  84.62%; F1:  73.33 17\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\n",
            "2020-07-29 14:42:24.257 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 83.0769\n",
            "2020-07-29 14:42:24.258 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 14:42:24.259 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 83.0769, \"ner_token_f1\": 92.9293}, \"time_spent\": \"0:00:36\", \"epochs_done\": 11, \"batches_seen\": 154, \"train_examples_seen\": 9394, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:27.359 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 445 tokens with 15 phrases; found: 15 phrases; correct: 0.\n",
            "\n",
            "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 2\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 6\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"ner_token_f1\": 100.0}, \"time_spent\": \"0:00:39\", \"epochs_done\": 12, \"batches_seen\": 168, \"train_examples_seen\": 10248, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.02483171064938818}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:27.589 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 34 phrases; correct: 0.\n",
            "\n",
            "precision:  76.47%; recall:  81.25%; FB1:  78.79\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 8\n",
            "\n",
            "\tcuisine: precision:  55.56%; recall:  76.92%; F1:  64.52 18\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\n",
            "2020-07-29 14:42:27.591 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 83.0769\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 78.7879, \"ner_token_f1\": 92.9293}, \"time_spent\": \"0:00:40\", \"epochs_done\": 12, \"batches_seen\": 168, \"train_examples_seen\": 10248, \"impatience\": 1, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:30.219 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 417 tokens with 12 phrases; found: 12 phrases; correct: 0.\n",
            "\n",
            "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 2\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 5\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"ner_token_f1\": 100.0}, \"time_spent\": \"0:00:42\", \"epochs_done\": 13, \"batches_seen\": 182, \"train_examples_seen\": 11102, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.009724704673447247}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:30.447 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 32 phrases; correct: 0.\n",
            "\n",
            "precision:  87.50%; recall:  87.50%; FB1:  87.50\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 8\n",
            "\n",
            "\tcuisine: precision:  75.00%; recall:  92.31%; F1:  82.76 16\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\n",
            "2020-07-29 14:42:30.451 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 87.5\n",
            "2020-07-29 14:42:30.451 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 14:42:30.452 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 87.5, \"ner_token_f1\": 92.9293}, \"time_spent\": \"0:00:42\", \"epochs_done\": 13, \"batches_seen\": 182, \"train_examples_seen\": 11102, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:33.504 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 447 tokens with 19 phrases; found: 19 phrases; correct: 0.\n",
            "\n",
            "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  100.00%; F1:  100.00 5\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\trestaurant_name: precision:  100.00%; recall:  100.00%; F1:  100.00 2\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 6\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"ner_token_f1\": 100.0}, \"time_spent\": \"0:00:46\", \"epochs_done\": 14, \"batches_seen\": 196, \"train_examples_seen\": 11956, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.006205307386283364}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:33.737 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 31 phrases; correct: 0.\n",
            "\n",
            "precision:  93.55%; recall:  90.62%; FB1:  92.06\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 8\n",
            "\n",
            "\tcuisine: precision:  86.67%; recall:  100.00%; F1:  92.86 15\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\n",
            "2020-07-29 14:42:33.740 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 92.0635\n",
            "2020-07-29 14:42:33.741 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 14:42:33.742 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 92.0635, \"ner_token_f1\": 92.9293}, \"time_spent\": \"0:00:46\", \"epochs_done\": 14, \"batches_seen\": 196, \"train_examples_seen\": 11956, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:36.796 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 385 tokens with 9 phrases; found: 9 phrases; correct: 0.\n",
            "\n",
            "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 2\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\trestaurant_name: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"ner_token_f1\": 100.0}, \"time_spent\": \"0:00:49\", \"epochs_done\": 15, \"batches_seen\": 210, \"train_examples_seen\": 12810, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.007044357114604541}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:37.40 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 31 phrases; correct: 0.\n",
            "\n",
            "precision:  93.55%; recall:  90.62%; FB1:  92.06\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 8\n",
            "\n",
            "\tcuisine: precision:  86.67%; recall:  100.00%; F1:  92.86 15\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\n",
            "2020-07-29 14:42:37.44 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 92.0635\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 92.0635, \"ner_token_f1\": 92.9293}, \"time_spent\": \"0:00:49\", \"epochs_done\": 15, \"batches_seen\": 210, \"train_examples_seen\": 12810, \"impatience\": 1, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:39.816 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 400 tokens with 6 phrases; found: 6 phrases; correct: 0.\n",
            "\n",
            "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 2\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"ner_token_f1\": 100.0}, \"time_spent\": \"0:00:52\", \"epochs_done\": 16, \"batches_seen\": 224, \"train_examples_seen\": 13664, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.025010778337933255}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:40.58 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 30 phrases; correct: 0.\n",
            "\n",
            "precision:  93.33%; recall:  87.50%; FB1:  90.32\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 8\n",
            "\n",
            "\tcuisine: precision:  85.71%; recall:  92.31%; F1:  88.89 14\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\n",
            "2020-07-29 14:42:40.60 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 92.0635\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 90.3226, \"ner_token_f1\": 91.8367}, \"time_spent\": \"0:00:52\", \"epochs_done\": 16, \"batches_seen\": 224, \"train_examples_seen\": 13664, \"impatience\": 2, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:42.776 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 370 tokens with 15 phrases; found: 15 phrases; correct: 0.\n",
            "\n",
            "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 6\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"ner_token_f1\": 100.0}, \"time_spent\": \"0:00:55\", \"epochs_done\": 17, \"batches_seen\": 238, \"train_examples_seen\": 14518, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.023841263260692358}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:43.16 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 30 phrases; correct: 0.\n",
            "\n",
            "precision:  90.00%; recall:  84.38%; FB1:  87.10\n",
            "\n",
            "\tcity: precision:  87.50%; recall:  87.50%; F1:  87.50 8\n",
            "\n",
            "\tcuisine: precision:  85.71%; recall:  92.31%; F1:  88.89 14\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\n",
            "2020-07-29 14:42:43.19 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 92.0635\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 87.0968, \"ner_token_f1\": 90.7216}, \"time_spent\": \"0:00:55\", \"epochs_done\": 17, \"batches_seen\": 238, \"train_examples_seen\": 14518, \"impatience\": 3, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:45.704 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 374 tokens with 12 phrases; found: 12 phrases; correct: 0.\n",
            "\n",
            "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 5\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"ner_token_f1\": 100.0}, \"time_spent\": \"0:00:58\", \"epochs_done\": 18, \"batches_seen\": 252, \"train_examples_seen\": 15372, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.016808906836169108}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:45.932 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 33 phrases; correct: 0.\n",
            "\n",
            "precision:  75.76%; recall:  78.12%; FB1:  76.92\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 8\n",
            "\n",
            "\tcuisine: precision:  52.94%; recall:  69.23%; F1:  60.00 17\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\n",
            "2020-07-29 14:42:45.935 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 92.0635\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 76.9231, \"ner_token_f1\": 91.8367}, \"time_spent\": \"0:00:58\", \"epochs_done\": 18, \"batches_seen\": 252, \"train_examples_seen\": 15372, \"impatience\": 4, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:48.802 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 497 tokens with 7 phrases; found: 7 phrases; correct: 0.\n",
            "\n",
            "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"ner_token_f1\": 100.0}, \"time_spent\": \"0:01:01\", \"epochs_done\": 19, \"batches_seen\": 266, \"train_examples_seen\": 16226, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.011997069824636648}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:49.38 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 30 phrases; correct: 0.\n",
            "\n",
            "precision:  86.67%; recall:  81.25%; FB1:  83.87\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 8\n",
            "\n",
            "\tcuisine: precision:  71.43%; recall:  76.92%; F1:  74.07 14\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\n",
            "2020-07-29 14:42:49.42 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 92.0635\n",
            "2020-07-29 14:42:49.137 INFO in 'deeppavlov.core.models.lr_scheduled_model'['lr_scheduled_model'] at line 429: New learning rate dividor = 10.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 83.871, \"ner_token_f1\": 90.7216}, \"time_spent\": \"0:01:01\", \"epochs_done\": 19, \"batches_seen\": 266, \"train_examples_seen\": 16226, \"impatience\": 5, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:51.979 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 458 tokens with 11 phrases; found: 11 phrases; correct: 0.\n",
            "\n",
            "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\trestaurant_name: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 2\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"ner_token_f1\": 100.0}, \"time_spent\": \"0:01:04\", \"epochs_done\": 20, \"batches_seen\": 280, \"train_examples_seen\": 17080, \"learning_rate\": 0.001, \"momentum\": null, \"loss\": 0.01381584073117535}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:52.216 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 31 phrases; correct: 0.\n",
            "\n",
            "precision:  87.10%; recall:  84.38%; FB1:  85.71\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 8\n",
            "\n",
            "\tcuisine: precision:  73.33%; recall:  84.62%; F1:  78.57 15\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\n",
            "2020-07-29 14:42:52.220 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 92.0635\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 85.7143, \"ner_token_f1\": 91.8367}, \"time_spent\": \"0:01:04\", \"epochs_done\": 20, \"batches_seen\": 280, \"train_examples_seen\": 17080, \"impatience\": 6, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:55.119 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 457 tokens with 9 phrases; found: 9 phrases; correct: 0.\n",
            "\n",
            "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 2\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\trestaurant_name: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"ner_token_f1\": 100.0}, \"time_spent\": \"0:01:07\", \"epochs_done\": 21, \"batches_seen\": 294, \"train_examples_seen\": 17934, \"learning_rate\": 0.001, \"momentum\": null, \"loss\": 0.005981394029212035}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:55.351 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 31 phrases; correct: 0.\n",
            "\n",
            "precision:  87.10%; recall:  84.38%; FB1:  85.71\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 8\n",
            "\n",
            "\tcuisine: precision:  73.33%; recall:  84.62%; F1:  78.57 15\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\n",
            "2020-07-29 14:42:55.355 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 92.0635\n",
            "2020-07-29 14:42:55.444 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 328: Ran out of patience\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 85.7143, \"ner_token_f1\": 91.8367}, \"time_spent\": \"0:01:07\", \"epochs_done\": 21, \"batches_seen\": 294, \"train_examples_seen\": 17934, \"impatience\": 7, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:42:55.699 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/word.dict]\n",
            "2020-07-29 14:42:55.701 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/tag.dict]\n",
            "2020-07-29 14:42:55.706 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/char.dict]\n",
            "2020-07-29 14:42:55.711 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n",
            "2020-07-29 14:43:29.103 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 760: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2020-07-29 14:43:29.183 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 760: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2020-07-29 14:43:30.610 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_conll2003/model_no_pos\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:43:31.40 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 31 phrases; correct: 0.\n",
            "\n",
            "precision:  93.55%; recall:  90.62%; FB1:  92.06\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 8\n",
            "\n",
            "\tcuisine: precision:  86.67%; recall:  100.00%; F1:  92.86 15\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 92.0635, \"ner_token_f1\": 92.9293}, \"time_spent\": \"0:00:01\"}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:43:31.319 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1846 tokens with 50 phrases; found: 49 phrases; correct: 0.\n",
            "\n",
            "precision:  83.67%; recall:  82.00%; FB1:  82.83\n",
            "\n",
            "\tcity: precision:  91.67%; recall:  84.62%; F1:  88.00 12\n",
            "\n",
            "\tcuisine: precision:  92.86%; recall:  92.86%; F1:  92.86 14\n",
            "\n",
            "\tdate: precision:  75.00%; recall:  50.00%; F1:  60.00 4\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  68.75%; recall:  84.62%; F1:  75.86 16\n",
            "\n",
            "\n",
            "2020-07-29 14:43:31.562 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/word.dict]\n",
            "2020-07-29 14:43:31.564 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/tag.dict]\n",
            "2020-07-29 14:43:31.567 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/char.dict]\n",
            "2020-07-29 14:43:31.568 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"test\": {\"eval_examples_count\": 267, \"metrics\": {\"ner_f1\": 82.8283, \"ner_token_f1\": 87.4372}, \"time_spent\": \"0:00:01\"}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:44:04.630 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 760: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2020-07-29 14:44:04.709 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 760: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2020-07-29 14:44:06.139 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_conll2003/model_no_pos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G01hfCemaI_C",
        "colab_type": "text"
      },
      "source": [
        "Ner performs OK for everything except the restaurants' name identification.  \n",
        "That's mostly because we avoid the usage of restaurants database here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PXzLz-Jaf4I",
        "colab_type": "text"
      },
      "source": [
        "Let's check the NER performance running some slotfilling experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eKIgrOqbfgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "json.dump(ner_config, open('ner_config.json', 'wt'))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTcFFxhAbxSx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "3aa18a0f-1c9e-44c5-cfd8-dc7bf2bca91b"
      },
      "source": [
        "import json\n",
        "from deeppavlov import configs\n",
        "\n",
        "from deeppavlov.core.common.file import read_json\n",
        "from deeppavlov import build_model\n",
        "\n",
        "slotfill_config = read_json(configs.ner.slotfill_dstc2)\n",
        "slotfill_config['dataset_reader']['class_name'] = \"md_yaml_dialogs_reader\"\n",
        "slotfill_config['metadata']['variables']['DATA_PATH'] = 'schema_resto_md_yaml'\n",
        "slotfill_config['metadata']['variables']['SLOT_VALS_PATH'] = 'schema_resto_md_yaml/slotfill.json'\n",
        "slotfill_config[\"chainer\"][\"pipe\"][-1][\"load_path\"] = \"schema_resto_md_yaml/slotfill.json\"\n",
        "slotfill_config[\"metadata\"][\"variables\"][\"NER_CONFIG_PATH\"] = \"ner_config.json\"\n",
        "slotfiller = build_model(slotfill_config, download=False)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:44:06.450 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/word.dict]\n",
            "2020-07-29 14:44:06.453 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/tag.dict]\n",
            "2020-07-29 14:44:06.454 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/char.dict]\n",
            "2020-07-29 14:44:06.456 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n",
            "2020-07-29 14:44:39.645 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 760: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2020-07-29 14:44:39.722 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 760: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2020-07-29 14:44:41.163 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_conll2003/model_no_pos\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:44:41.274 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 45: Load path '/content/dp_big_demo_dir/schema_resto_md_yaml/slotfill.json' differs from save path '/root/.deeppavlov/models/slotfill_dstc2/model' in 'infer' mode for DstcSlotFillingNetwork.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6slj0dKFdXZC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9dfaf75e-cde2-4966-d61d-8c63231a7119"
      },
      "source": [
        "slotfiller([\"i'm looking for a thai food somewhere in SFO\"])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'city': 'SFO', 'cuisine': 'Thai'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZG8Zk-ypankD",
        "colab_type": "text"
      },
      "source": [
        "Seems OK. Let's save our slotfiller config and train and evaluate the restaurants bot, finally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DKCnXjGd6Q0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "json.dump(slotfill_config, open('slotfill_config.json', 'wt'))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CkliRfVdlxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from deeppavlov import configs\n",
        "from deeppavlov.core.common.file import read_json\n",
        "\n",
        "\n",
        "gobot_config = read_json(configs.go_bot.gobot_md_yaml_minimal)\n",
        "gobot_config['chainer']['pipe'][-1]['slot_filler'] = {\"config_path\": \"slotfill_config.json\"}\n",
        "\n",
        "gobot_config['metadata']['variables']['DATA_PATH'] = 'schema_resto_md_yaml'\n",
        "gobot_config['metadata']['variables']['MODEL_PATH'] = '.'"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4HWEXlEeW92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp schema_resto_md_yaml/stories.md schema_resto_md_yaml/stories-trn.md\n",
        "!cp schema_resto_md_yaml/stories.md schema_resto_md_yaml/stories-tst.md\n",
        "!cp schema_resto_md_yaml/stories.md schema_resto_md_yaml/stories-val.md"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8dM5w1tkCgf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!echo \"{}\" > schema_resto_md_yaml/dstc2-actions2slots.json  # a hack that will be redundant in future versions. keep an empty json file in the data folder"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMbazF8ad6_N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "72973d10-4a6f-42af-f396-cd77757cbc51"
      },
      "source": [
        "from deeppavlov import train_model\n",
        "\n",
        "train_model(gobot_config, download=False);"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:44:46.811 INFO in 'deeppavlov.dataset_readers.md_yaml_dialogs_reader'['md_yaml_dialogs_reader'] at line 123: INSIDE MLU_MD_DialogsDatasetReader._read_domain_knowledge(): reading domain knowledge from /content/dp_big_demo_dir/schema_resto_md_yaml/domain.yml\n",
            "2020-07-29 14:44:46.978 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmpegk9s_lo]\n",
            "2020-07-29 14:44:47.80 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmpp4sn4fbf]\n",
            "2020-07-29 14:44:47.187 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmphy0gjblt]\n",
            "2020-07-29 14:44:47.206 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /content/dp_big_demo_dir/word.dict]\n",
            "2020-07-29 14:44:47.209 INFO in 'deeppavlov.dataset_readers.md_yaml_dialogs_reader'['md_yaml_dialogs_reader'] at line 123: INSIDE MLU_MD_DialogsDatasetReader._read_domain_knowledge(): reading domain knowledge from /content/dp_big_demo_dir/schema_resto_md_yaml/domain.yml\n",
            "2020-07-29 14:44:47.386 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmpogrvl3zi]\n",
            "2020-07-29 14:44:47.492 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmpyxadtshe]\n",
            "2020-07-29 14:44:47.597 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmp7q78wp78]\n",
            "2020-07-29 14:44:47.782 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/word.dict]\n",
            "2020-07-29 14:44:47.784 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/tag.dict]\n",
            "2020-07-29 14:44:47.786 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/char.dict]\n",
            "2020-07-29 14:44:47.793 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n",
            "2020-07-29 14:45:21.286 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 760: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2020-07-29 14:45:21.366 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 760: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2020-07-29 14:45:22.792 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_conll2003/model_no_pos\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:45:22.892 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 45: Load path '/content/dp_big_demo_dir/schema_resto_md_yaml/slotfill.json' differs from save path '/root/.deeppavlov/models/slotfill_dstc2/model' in 'infer' mode for DstcSlotFillingNetwork.\n",
            "2020-07-29 14:45:22.894 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n",
            "2020-07-29 14:45:56.593 INFO in 'deeppavlov.models.go_bot.policy.policy_network'['policy_network'] at line 89: INSIDE PolicyNetwork init(). Initializing PolicyNetwork from scratch.\n",
            "2020-07-29 14:45:59.725 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 198: Initial best per_item_action_accuracy of 0.0024\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.0024}, \"time_spent\": \"0:00:04\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.2799}, \"time_spent\": \"0:00:09\", \"epochs_done\": 0, \"batches_seen\": 15, \"train_examples_seen\": 60, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 2.740983168284098}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:46:07.693 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best per_item_action_accuracy of 0.2799\n",
            "2020-07-29 14:46:07.697 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 14:46:07.698 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/dp_big_demo_dir/model/policy]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.2799}, \"time_spent\": \"0:00:12\", \"epochs_done\": 0, \"batches_seen\": 15, \"train_examples_seen\": 60, \"impatience\": 0, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.4522}, \"time_spent\": \"0:00:16\", \"epochs_done\": 1, \"batches_seen\": 30, \"train_examples_seen\": 117, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 2.152272041638692}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:46:15.423 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best per_item_action_accuracy of 0.4522\n",
            "2020-07-29 14:46:15.424 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 14:46:15.425 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/dp_big_demo_dir/model/policy]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.4522}, \"time_spent\": \"0:00:19\", \"epochs_done\": 1, \"batches_seen\": 30, \"train_examples_seen\": 117, \"impatience\": 0, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.5455}, \"time_spent\": \"0:00:24\", \"epochs_done\": 2, \"batches_seen\": 45, \"train_examples_seen\": 174, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 1.645211402575175}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:46:23.239 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best per_item_action_accuracy of 0.5455\n",
            "2020-07-29 14:46:23.240 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 14:46:23.245 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/dp_big_demo_dir/model/policy]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.5455}, \"time_spent\": \"0:00:27\", \"epochs_done\": 2, \"batches_seen\": 45, \"train_examples_seen\": 174, \"impatience\": 0, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.5359}, \"time_spent\": \"0:00:32\", \"epochs_done\": 2, \"batches_seen\": 60, \"train_examples_seen\": 234, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 1.3486886103947957}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:46:31.124 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 0.5455\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.5359}, \"time_spent\": \"0:00:35\", \"epochs_done\": 2, \"batches_seen\": 60, \"train_examples_seen\": 234, \"impatience\": 1, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.5263}, \"time_spent\": \"0:00:40\", \"epochs_done\": 3, \"batches_seen\": 75, \"train_examples_seen\": 291, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 1.2267640749613444}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:46:38.912 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 0.5455\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.5263}, \"time_spent\": \"0:00:43\", \"epochs_done\": 3, \"batches_seen\": 75, \"train_examples_seen\": 291, \"impatience\": 2, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.5598}, \"time_spent\": \"0:00:48\", \"epochs_done\": 4, \"batches_seen\": 90, \"train_examples_seen\": 348, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 1.1717514991760254}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:46:46.607 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best per_item_action_accuracy of 0.5598\n",
            "2020-07-29 14:46:46.608 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 14:46:46.610 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/dp_big_demo_dir/model/policy]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.5598}, \"time_spent\": \"0:00:51\", \"epochs_done\": 4, \"batches_seen\": 90, \"train_examples_seen\": 348, \"impatience\": 0, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.5825}, \"time_spent\": \"0:00:55\", \"epochs_done\": 4, \"batches_seen\": 105, \"train_examples_seen\": 408, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.9592454075813294}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:46:54.509 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best per_item_action_accuracy of 0.5825\n",
            "2020-07-29 14:46:54.510 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 14:46:54.511 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/dp_big_demo_dir/model/policy]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.5825}, \"time_spent\": \"0:00:58\", \"epochs_done\": 4, \"batches_seen\": 105, \"train_examples_seen\": 408, \"impatience\": 0, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.573}, \"time_spent\": \"0:01:03\", \"epochs_done\": 5, \"batches_seen\": 120, \"train_examples_seen\": 465, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.9182585994402568}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:47:02.330 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 0.5825\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.573}, \"time_spent\": \"0:01:06\", \"epochs_done\": 5, \"batches_seen\": 120, \"train_examples_seen\": 465, \"impatience\": 1, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6065}, \"time_spent\": \"0:01:11\", \"epochs_done\": 6, \"batches_seen\": 135, \"train_examples_seen\": 522, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.9086218237876892}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:47:10.76 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best per_item_action_accuracy of 0.6065\n",
            "2020-07-29 14:47:10.76 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 14:47:10.77 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/dp_big_demo_dir/model/policy]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6065}, \"time_spent\": \"0:01:14\", \"epochs_done\": 6, \"batches_seen\": 135, \"train_examples_seen\": 522, \"impatience\": 0, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6172}, \"time_spent\": \"0:01:19\", \"epochs_done\": 6, \"batches_seen\": 150, \"train_examples_seen\": 582, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.7683210690816243}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:47:18.70 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best per_item_action_accuracy of 0.6172\n",
            "2020-07-29 14:47:18.71 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 14:47:18.72 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/dp_big_demo_dir/model/policy]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6172}, \"time_spent\": \"0:01:22\", \"epochs_done\": 6, \"batches_seen\": 150, \"train_examples_seen\": 582, \"impatience\": 0, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.683}, \"time_spent\": \"0:01:27\", \"epochs_done\": 7, \"batches_seen\": 165, \"train_examples_seen\": 639, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.7187162121136983}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:47:25.924 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best per_item_action_accuracy of 0.683\n",
            "2020-07-29 14:47:25.925 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 14:47:25.926 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/dp_big_demo_dir/model/policy]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.683}, \"time_spent\": \"0:01:30\", \"epochs_done\": 7, \"batches_seen\": 165, \"train_examples_seen\": 639, \"impatience\": 0, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6435}, \"time_spent\": \"0:01:35\", \"epochs_done\": 8, \"batches_seen\": 180, \"train_examples_seen\": 696, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.758539076646169}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:47:33.648 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 0.683\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6435}, \"time_spent\": \"0:01:38\", \"epochs_done\": 8, \"batches_seen\": 180, \"train_examples_seen\": 696, \"impatience\": 1, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.616}, \"time_spent\": \"0:01:42\", \"epochs_done\": 8, \"batches_seen\": 195, \"train_examples_seen\": 756, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.6558904687563578}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:47:41.296 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 0.683\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.616}, \"time_spent\": \"0:01:45\", \"epochs_done\": 8, \"batches_seen\": 195, \"train_examples_seen\": 756, \"impatience\": 2, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6603}, \"time_spent\": \"0:01:50\", \"epochs_done\": 9, \"batches_seen\": 210, \"train_examples_seen\": 813, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.5755451162656148}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:47:48.984 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 0.683\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6603}, \"time_spent\": \"0:01:53\", \"epochs_done\": 9, \"batches_seen\": 210, \"train_examples_seen\": 813, \"impatience\": 3, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6794}, \"time_spent\": \"0:01:57\", \"epochs_done\": 10, \"batches_seen\": 225, \"train_examples_seen\": 870, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.5978685140609741}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:47:56.520 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 0.683\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6794}, \"time_spent\": \"0:02:00\", \"epochs_done\": 10, \"batches_seen\": 225, \"train_examples_seen\": 870, \"impatience\": 4, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6794}, \"time_spent\": \"0:02:05\", \"epochs_done\": 10, \"batches_seen\": 240, \"train_examples_seen\": 930, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.5723080992698669}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:48:04.254 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 0.683\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6794}, \"time_spent\": \"0:02:08\", \"epochs_done\": 10, \"batches_seen\": 240, \"train_examples_seen\": 930, \"impatience\": 5, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6806}, \"time_spent\": \"0:02:13\", \"epochs_done\": 11, \"batches_seen\": 255, \"train_examples_seen\": 987, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.49052075346310936}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:48:11.885 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 0.683\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6806}, \"time_spent\": \"0:02:16\", \"epochs_done\": 11, \"batches_seen\": 255, \"train_examples_seen\": 987, \"impatience\": 6, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6519}, \"time_spent\": \"0:02:21\", \"epochs_done\": 12, \"batches_seen\": 270, \"train_examples_seen\": 1044, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.5327563842137655}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:48:19.781 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 0.683\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6519}, \"time_spent\": \"0:02:24\", \"epochs_done\": 12, \"batches_seen\": 270, \"train_examples_seen\": 1044, \"impatience\": 7, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6794}, \"time_spent\": \"0:02:29\", \"epochs_done\": 12, \"batches_seen\": 285, \"train_examples_seen\": 1104, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.49575189550717674}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:48:27.777 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 0.683\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6794}, \"time_spent\": \"0:02:32\", \"epochs_done\": 12, \"batches_seen\": 285, \"train_examples_seen\": 1104, \"impatience\": 8, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6986}, \"time_spent\": \"0:02:36\", \"epochs_done\": 13, \"batches_seen\": 300, \"train_examples_seen\": 1161, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.4779082477092743}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:48:35.448 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best per_item_action_accuracy of 0.6986\n",
            "2020-07-29 14:48:35.451 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 14:48:35.452 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/dp_big_demo_dir/model/policy]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6986}, \"time_spent\": \"0:02:39\", \"epochs_done\": 13, \"batches_seen\": 300, \"train_examples_seen\": 1161, \"impatience\": 0, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.7057}, \"time_spent\": \"0:02:44\", \"epochs_done\": 14, \"batches_seen\": 315, \"train_examples_seen\": 1218, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.44928969542185465}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:48:43.256 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best per_item_action_accuracy of 0.7057\n",
            "2020-07-29 14:48:43.257 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 14:48:43.258 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/dp_big_demo_dir/model/policy]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.7057}, \"time_spent\": \"0:02:47\", \"epochs_done\": 14, \"batches_seen\": 315, \"train_examples_seen\": 1218, \"impatience\": 0, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6962}, \"time_spent\": \"0:02:52\", \"epochs_done\": 14, \"batches_seen\": 330, \"train_examples_seen\": 1275, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.431477814912796}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:48:50.999 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 0.7057\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6962}, \"time_spent\": \"0:02:55\", \"epochs_done\": 14, \"batches_seen\": 330, \"train_examples_seen\": 1275, \"impatience\": 1, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6926}, \"time_spent\": \"0:03:00\", \"epochs_done\": 15, \"batches_seen\": 345, \"train_examples_seen\": 1335, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.42873285214106244}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:48:58.680 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 0.7057\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6926}, \"time_spent\": \"0:03:03\", \"epochs_done\": 15, \"batches_seen\": 345, \"train_examples_seen\": 1335, \"impatience\": 2, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.7022}, \"time_spent\": \"0:03:07\", \"epochs_done\": 16, \"batches_seen\": 360, \"train_examples_seen\": 1392, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.4241398374239604}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:49:06.342 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 0.7057\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.7022}, \"time_spent\": \"0:03:10\", \"epochs_done\": 16, \"batches_seen\": 360, \"train_examples_seen\": 1392, \"impatience\": 3, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.7057}, \"time_spent\": \"0:03:15\", \"epochs_done\": 17, \"batches_seen\": 375, \"train_examples_seen\": 1449, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.423928838968277}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:49:13.944 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 0.7057\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.7057}, \"time_spent\": \"0:03:18\", \"epochs_done\": 17, \"batches_seen\": 375, \"train_examples_seen\": 1449, \"impatience\": 4, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6818}, \"time_spent\": \"0:03:23\", \"epochs_done\": 17, \"batches_seen\": 390, \"train_examples_seen\": 1509, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.3831144710381826}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:49:21.636 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 0.7057\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6818}, \"time_spent\": \"0:03:26\", \"epochs_done\": 17, \"batches_seen\": 390, \"train_examples_seen\": 1509, \"impatience\": 5, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.7201}, \"time_spent\": \"0:03:30\", \"epochs_done\": 18, \"batches_seen\": 405, \"train_examples_seen\": 1566, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.39419552087783816}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:49:29.278 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best per_item_action_accuracy of 0.7201\n",
            "2020-07-29 14:49:29.280 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 14:49:29.283 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/dp_big_demo_dir/model/policy]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.7201}, \"time_spent\": \"0:03:33\", \"epochs_done\": 18, \"batches_seen\": 405, \"train_examples_seen\": 1566, \"impatience\": 0, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.7249}, \"time_spent\": \"0:03:38\", \"epochs_done\": 19, \"batches_seen\": 420, \"train_examples_seen\": 1623, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.36469561656316124}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:49:37.1 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best per_item_action_accuracy of 0.7249\n",
            "2020-07-29 14:49:37.2 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 14:49:37.2 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/dp_big_demo_dir/model/policy]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.7249}, \"time_spent\": \"0:03:41\", \"epochs_done\": 19, \"batches_seen\": 420, \"train_examples_seen\": 1623, \"impatience\": 0, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6818}, \"time_spent\": \"0:03:46\", \"epochs_done\": 19, \"batches_seen\": 435, \"train_examples_seen\": 1683, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.34039169748624165}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:49:44.905 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 0.7249\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6818}, \"time_spent\": \"0:03:49\", \"epochs_done\": 19, \"batches_seen\": 435, \"train_examples_seen\": 1683, \"impatience\": 1, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.7141}, \"time_spent\": \"0:03:53\", \"epochs_done\": 20, \"batches_seen\": 450, \"train_examples_seen\": 1740, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.34851667086283367}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:49:52.610 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 0.7249\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.7141}, \"time_spent\": \"0:03:57\", \"epochs_done\": 20, \"batches_seen\": 450, \"train_examples_seen\": 1740, \"impatience\": 2, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.7069}, \"time_spent\": \"0:04:01\", \"epochs_done\": 21, \"batches_seen\": 465, \"train_examples_seen\": 1797, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.3246365418036779}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:50:00.296 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 0.7249\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.7069}, \"time_spent\": \"0:04:04\", \"epochs_done\": 21, \"batches_seen\": 465, \"train_examples_seen\": 1797, \"impatience\": 3, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.689}, \"time_spent\": \"0:04:09\", \"epochs_done\": 21, \"batches_seen\": 480, \"train_examples_seen\": 1857, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.31312116583188376}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:50:08.32 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 0.7249\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.689}, \"time_spent\": \"0:04:12\", \"epochs_done\": 21, \"batches_seen\": 480, \"train_examples_seen\": 1857, \"impatience\": 4, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6806}, \"time_spent\": \"0:04:17\", \"epochs_done\": 22, \"batches_seen\": 495, \"train_examples_seen\": 1914, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.3024123271306356}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:50:15.651 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 0.7249\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6806}, \"time_spent\": \"0:04:20\", \"epochs_done\": 22, \"batches_seen\": 495, \"train_examples_seen\": 1914, \"impatience\": 5, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.7333}, \"time_spent\": \"0:04:24\", \"epochs_done\": 23, \"batches_seen\": 510, \"train_examples_seen\": 1971, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.31215458512306216}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:50:23.226 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best per_item_action_accuracy of 0.7333\n",
            "2020-07-29 14:50:23.227 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 14:50:23.231 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/dp_big_demo_dir/model/policy]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.7333}, \"time_spent\": \"0:04:27\", \"epochs_done\": 23, \"batches_seen\": 510, \"train_examples_seen\": 1971, \"impatience\": 0, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.7105}, \"time_spent\": \"0:04:32\", \"epochs_done\": 23, \"batches_seen\": 525, \"train_examples_seen\": 2031, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.2974122275908788}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:50:31.112 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 0.7333\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.7105}, \"time_spent\": \"0:04:35\", \"epochs_done\": 23, \"batches_seen\": 525, \"train_examples_seen\": 2031, \"impatience\": 1, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.695}, \"time_spent\": \"0:04:40\", \"epochs_done\": 24, \"batches_seen\": 540, \"train_examples_seen\": 2088, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.30502782861391703}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:50:38.718 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 0.7333\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.695}, \"time_spent\": \"0:04:43\", \"epochs_done\": 24, \"batches_seen\": 540, \"train_examples_seen\": 2088, \"impatience\": 2, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.701}, \"time_spent\": \"0:04:47\", \"epochs_done\": 25, \"batches_seen\": 555, \"train_examples_seen\": 2145, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.313426473736763}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:50:46.279 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 0.7333\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.701}, \"time_spent\": \"0:04:50\", \"epochs_done\": 25, \"batches_seen\": 555, \"train_examples_seen\": 2145, \"impatience\": 3, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.677}, \"time_spent\": \"0:04:55\", \"epochs_done\": 25, \"batches_seen\": 570, \"train_examples_seen\": 2205, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.3137074182430903}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:50:54.48 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 0.7333\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.677}, \"time_spent\": \"0:04:58\", \"epochs_done\": 25, \"batches_seen\": 570, \"train_examples_seen\": 2205, \"impatience\": 4, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.7225}, \"time_spent\": \"0:05:03\", \"epochs_done\": 26, \"batches_seen\": 585, \"train_examples_seen\": 2262, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.27483218908309937}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:51:01.706 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 0.7333\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.7225}, \"time_spent\": \"0:05:06\", \"epochs_done\": 26, \"batches_seen\": 585, \"train_examples_seen\": 2262, \"impatience\": 5, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.701}, \"time_spent\": \"0:05:10\", \"epochs_done\": 27, \"batches_seen\": 600, \"train_examples_seen\": 2319, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.29599379897117617}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:51:09.410 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 0.7333\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.701}, \"time_spent\": \"0:05:13\", \"epochs_done\": 27, \"batches_seen\": 600, \"train_examples_seen\": 2319, \"impatience\": 6, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.7117}, \"time_spent\": \"0:05:18\", \"epochs_done\": 27, \"batches_seen\": 615, \"train_examples_seen\": 2379, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.29220342139403027}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:51:17.230 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 0.7333\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.7117}, \"time_spent\": \"0:05:21\", \"epochs_done\": 27, \"batches_seen\": 615, \"train_examples_seen\": 2379, \"impatience\": 7, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6902}, \"time_spent\": \"0:05:26\", \"epochs_done\": 28, \"batches_seen\": 630, \"train_examples_seen\": 2436, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.29650667011737825}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:51:24.813 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 0.7333\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6902}, \"time_spent\": \"0:05:29\", \"epochs_done\": 28, \"batches_seen\": 630, \"train_examples_seen\": 2436, \"impatience\": 8, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6627}, \"time_spent\": \"0:05:33\", \"epochs_done\": 29, \"batches_seen\": 645, \"train_examples_seen\": 2493, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.28341998855272926}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:51:32.378 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 0.7333\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6627}, \"time_spent\": \"0:05:36\", \"epochs_done\": 29, \"batches_seen\": 645, \"train_examples_seen\": 2493, \"impatience\": 9, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.7321}, \"time_spent\": \"0:05:41\", \"epochs_done\": 29, \"batches_seen\": 660, \"train_examples_seen\": 2550, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.29440933068593345}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:51:39.998 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 0.7333\n",
            "2020-07-29 14:51:40.0 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 307: Ran out of patience\n",
            "2020-07-29 14:51:40.127 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/dp_big_demo_dir/word.dict]\n",
            "2020-07-29 14:51:40.130 INFO in 'deeppavlov.dataset_readers.md_yaml_dialogs_reader'['md_yaml_dialogs_reader'] at line 123: INSIDE MLU_MD_DialogsDatasetReader._read_domain_knowledge(): reading domain knowledge from /content/dp_big_demo_dir/schema_resto_md_yaml/domain.yml\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.7321}, \"time_spent\": \"0:05:44\", \"epochs_done\": 29, \"batches_seen\": 660, \"train_examples_seen\": 2550, \"impatience\": 10, \"patience_limit\": 10}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:51:40.291 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmp5yd_i8kq]\n",
            "2020-07-29 14:51:40.398 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmpw6bcgw8d]\n",
            "2020-07-29 14:51:40.508 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmptqtkc8vs]\n",
            "2020-07-29 14:51:40.694 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/word.dict]\n",
            "2020-07-29 14:51:40.696 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/tag.dict]\n",
            "2020-07-29 14:51:40.697 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/char.dict]\n",
            "2020-07-29 14:51:40.699 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n",
            "2020-07-29 14:52:13.397 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 760: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2020-07-29 14:52:13.474 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 760: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2020-07-29 14:52:14.926 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_conll2003/model_no_pos\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:52:15.34 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 45: Load path '/content/dp_big_demo_dir/schema_resto_md_yaml/slotfill.json' differs from save path '/root/.deeppavlov/models/slotfill_dstc2/model' in 'infer' mode for DstcSlotFillingNetwork.\n",
            "2020-07-29 14:52:15.37 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n",
            "2020-07-29 14:52:48.968 INFO in 'deeppavlov.models.go_bot.policy.policy_network'['policy_network'] at line 86: INSIDE PolicyNetwork init(). Initializing PolicyNetwork from checkpoint.\n",
            "2020-07-29 14:52:48.973 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/dp_big_demo_dir/model/policy]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/dp_big_demo_dir/model/policy\n",
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.7333}, \"time_spent\": \"0:00:04\"}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:52:55.247 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/dp_big_demo_dir/word.dict]\n",
            "2020-07-29 14:52:55.250 INFO in 'deeppavlov.dataset_readers.md_yaml_dialogs_reader'['md_yaml_dialogs_reader'] at line 123: INSIDE MLU_MD_DialogsDatasetReader._read_domain_knowledge(): reading domain knowledge from /content/dp_big_demo_dir/schema_resto_md_yaml/domain.yml\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"test\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.7333}, \"time_spent\": \"0:00:03\"}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:52:55.417 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmpb30b43mx]\n",
            "2020-07-29 14:52:55.521 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmpe1awpj25]\n",
            "2020-07-29 14:52:55.624 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmpyajukubt]\n",
            "2020-07-29 14:52:55.810 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/word.dict]\n",
            "2020-07-29 14:52:55.812 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/tag.dict]\n",
            "2020-07-29 14:52:55.815 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/char.dict]\n",
            "2020-07-29 14:52:55.818 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n",
            "2020-07-29 14:53:28.929 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 760: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2020-07-29 14:53:29.8 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 760: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2020-07-29 14:53:30.457 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_conll2003/model_no_pos\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:53:30.573 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 45: Load path '/content/dp_big_demo_dir/schema_resto_md_yaml/slotfill.json' differs from save path '/root/.deeppavlov/models/slotfill_dstc2/model' in 'infer' mode for DstcSlotFillingNetwork.\n",
            "2020-07-29 14:53:30.575 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n",
            "2020-07-29 14:54:04.568 INFO in 'deeppavlov.models.go_bot.policy.policy_network'['policy_network'] at line 86: INSIDE PolicyNetwork init(). Initializing PolicyNetwork from checkpoint.\n",
            "2020-07-29 14:54:04.573 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/dp_big_demo_dir/model/policy]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/dp_big_demo_dir/model/policy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tk6inTKkeOql",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "9494ef9a-e660-4ed9-beac-30956485ad7d"
      },
      "source": [
        "bot = build_model(gobot_config)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:54:04.719 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/dp_big_demo_dir/word.dict]\n",
            "2020-07-29 14:54:04.722 INFO in 'deeppavlov.dataset_readers.md_yaml_dialogs_reader'['md_yaml_dialogs_reader'] at line 123: INSIDE MLU_MD_DialogsDatasetReader._read_domain_knowledge(): reading domain knowledge from /content/dp_big_demo_dir/schema_resto_md_yaml/domain.yml\n",
            "2020-07-29 14:54:04.892 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmpzt7zsk9v]\n",
            "2020-07-29 14:54:04.996 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmpk7sfljqx]\n",
            "2020-07-29 14:54:05.108 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmp33edcyxb]\n",
            "2020-07-29 14:54:05.297 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/word.dict]\n",
            "2020-07-29 14:54:05.300 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/tag.dict]\n",
            "2020-07-29 14:54:05.302 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/char.dict]\n",
            "2020-07-29 14:54:05.304 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n",
            "2020-07-29 14:54:37.905 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 760: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2020-07-29 14:54:37.982 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 760: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2020-07-29 14:54:39.420 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_conll2003/model_no_pos\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 14:54:39.528 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 45: Load path '/content/dp_big_demo_dir/schema_resto_md_yaml/slotfill.json' differs from save path '/root/.deeppavlov/models/slotfill_dstc2/model' in 'infer' mode for DstcSlotFillingNetwork.\n",
            "2020-07-29 14:54:39.530 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n",
            "2020-07-29 14:55:13.261 INFO in 'deeppavlov.models.go_bot.policy.policy_network'['policy_network'] at line 86: INSIDE PolicyNetwork init(). Initializing PolicyNetwork from checkpoint.\n",
            "2020-07-29 14:55:13.266 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/dp_big_demo_dir/model/policy]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/dp_big_demo_dir/model/policy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2Iv0GNgfjlM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "63cc4aff-cabc-4e50-c3d3-89a37e081ef8"
      },
      "source": [
        "bot.reset()\n",
        "\n",
        "bot([\"Hey!\"])[0][0].actions_tuple"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('utter_hi',)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKwg9N2zbD0B",
        "colab_type": "text"
      },
      "source": [
        "Ok the bot performs OK on greeting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c-oNomgswak",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "15bfaadb-0dd0-4bf6-ff86-d69722a9bdf6"
      },
      "source": [
        "bot([\"I'd like to find a restaurant for this evening\"])[0][0].actions_tuple"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('utter_REQUEST_Cuisine',)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxJwUqtCbJ6N",
        "colab_type": "text"
      },
      "source": [
        "The bot asks for an inevitably necessary information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otpYIs_khwPw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f3302ab4-9a1c-4dd5-abfd-31ea75d4bb51"
      },
      "source": [
        "bot([\"Somewhere in Oakland, sushi and for two people please\"])[0][0].actions_tuple"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('utter_OFFER_RestaurantName', 'OFFER_City')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4Ab-S4WbUJL",
        "colab_type": "text"
      },
      "source": [
        "And so on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51ViTAFjtZTq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3e40fa36-e07d-4982-87e6-8c6c74d85436"
      },
      "source": [
        "bot([\"Cool! That's what I was looking for, thanks!\"])[0][0].actions_tuple"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('utter_REQUEST_Time',)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIgU4aSSbmlS",
        "colab_type": "text"
      },
      "source": [
        "Let's say goodbye to our bot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNrBveyzhw7V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "aade7fd8-d070-407d-d09e-1e74e56aef93"
      },
      "source": [
        "bot([\"Bye bot\"])[0][0].actions_tuple"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('utter_REQUEST_Time',)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B--vLcEBbpRp",
        "colab_type": "text"
      },
      "source": [
        "After the goodbye bot does perform uninterpretable. That's what most of recurrent system do after the end of the sequence cause no one reaches that poing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4ASqT_Fu4TH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fd2082dc-3cb6-44aa-a106-4d0467ebded9"
      },
      "source": [
        "bot([\"Bye bot\"])[0][0].actions_tuple"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('start',)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ug6-3fYwb-BX",
        "colab_type": "text"
      },
      "source": [
        "## Final words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzcVEXleb_aU",
        "colab_type": "text"
      },
      "source": [
        "More of in-depth examples of goal-oriented bots and their features are coming with future releases, stay tuned!"
      ]
    }
  ]
}
