{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gobot md yaml configs tutorial.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPhzlczdiyx4RYjSomdoEVa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/oserikov/4406dea7f18328a5fe9e78d4e17bb9d5/gobot-md-yaml-configs-tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jj5nbxnPbz6D",
        "colab_type": "text"
      },
      "source": [
        "# Using Markdown & YAML to configure deeppavlov GO-bot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRO97JLXb8j5",
        "colab_type": "text"
      },
      "source": [
        "This tutorial notebook illustrates the way to configure a goal-oriented bot using 3 config files:\n",
        "* `stories.md` (or `stories-{trn, tst, val}.md` but these are just subsamples)\n",
        "* `nlu.md`\n",
        "* `domain.yml`\n",
        "\n",
        "The purpose of these files is briefly described below and the files formats desctiptions are below too.  \n",
        "One could scroll down to Demo sections to take a look at the example files in the working scenarios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWP08HJGnCDo",
        "colab_type": "text"
      },
      "source": [
        "## The purpose of `.md`, `.yml` config files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_NQHZOqcwcr",
        "colab_type": "text"
      },
      "source": [
        "### `stories.md`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3HWMZPrg4V1",
        "colab_type": "text"
      },
      "source": [
        "`stories.md` is to provide the **dialogues dataset** for model to train on. \n",
        "\n",
        "The dialogues are  \n",
        "not the sequences of user utterances *texts* and respective system replies *texts*  \n",
        "but the *intent + slots* user utterances *labels* and respective system replies *labels*.\n",
        "\n",
        "This is so to distinguish the NLU-NLG tasks from the actual dialogues storytelling experience: one should be able to describe just the scripts of dialogues to the system."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0oZHwh4K6PG",
        "colab_type": "text"
      },
      "source": [
        "#### format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad2ekquvK8oo",
        "colab_type": "text"
      },
      "source": [
        "Stories file is a markdown file of the following format:\n",
        "\n",
        "```markdown\n",
        "## story_title(not used by algorithm, but useful to work with for humans)\n",
        "* user_action_label{\"1st_slot_present_in_action\": \"slot1_value\", .., \"Nth_slot_present_in_action\": \"slotN_value\"}\n",
        " - system_respective_utterance\n",
        "* another_user_action_of_the_same_format\n",
        "  - another_system_response\n",
        "...\n",
        "\n",
        "## another_story_title\n",
        "...\n",
        "\n",
        "```\n",
        "\n",
        "**See examples below in this tutorial**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nhqxjj_Pedlo",
        "colab_type": "text"
      },
      "source": [
        "### `nlu.md`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zK1TuEvg6KJ",
        "colab_type": "text"
      },
      "source": [
        "`nlu.md` is contrariwise to provide the **NLU training set** irrespective of the dialogues scripts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVR4J_UNMAgq",
        "colab_type": "text"
      },
      "source": [
        "#### format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEj0G5ciMBtA",
        "colab_type": "text"
      },
      "source": [
        "NLU file is a markdown file of the following format:\n",
        "\n",
        "```markdown\n",
        "## intent:possible_user_action_label_1\n",
        "- An example of user text that has the possible_user_action_label_1 action label\n",
        "- Another example of user text that has the possible_user_action_label_1 action label\n",
        "...\n",
        "\n",
        "## intent:possible_user_action_label_N\n",
        "- An example of user text that has the (possible_user_action_label_N)[action_label] action label\n",
        "<!-- Slotfilling dataset is provided as an inline markup of user texts -->\n",
        "...\n",
        "\n",
        "```\n",
        "\n",
        "**See examples below in this tutorial**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-wQb3XMfqVJ",
        "colab_type": "text"
      },
      "source": [
        "### `domain.yml`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIlJd3FIg8Hg",
        "colab_type": "text"
      },
      "source": [
        "`domain.yml` is to desribe the task-specific domain and serves two purposes:\n",
        "* provide the NLG templates\n",
        "* provide some specific configuration of the NLU "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5qoE7NnNTEg",
        "colab_type": "text"
      },
      "source": [
        "#### format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gl5QCyVMOpU9",
        "colab_type": "text"
      },
      "source": [
        "Domain file is a YAML file of the following format:\n",
        "\n",
        "```yaml\n",
        "# slots section lists the possible slot names (aka slot types) \n",
        "# that are used in the domain (i.e. relevant for bot's tasks)\n",
        "# currently only type: text is supported\n",
        "slots:\n",
        "  slot1_name:\n",
        "    type: text\n",
        "  ...\n",
        "  slotN_name:\n",
        "    type: text\n",
        "\n",
        "# entities list now follows the slots list 2nd level keys \n",
        "# and is present to support upcoming features. Stay tuned for updates with this!\n",
        "entities:\n",
        "- slot1_name\n",
        "...\n",
        "- slotN_name\n",
        "\n",
        "# intents section lists the intents that can appear in the stories\n",
        "# being kept together they do describe the user-side part of go-bot's experience\n",
        "intents:\n",
        "  - user_action_label\n",
        "  - another_user_action_of_the_same_format\n",
        "  ...\n",
        "\n",
        "# responses section lists the system response templates.\n",
        "# Despite system response' titles being usually informative themselves\n",
        "#   (one could even find them more appropriate when no actual \"Natural Language\" is needed \n",
        "#    (e.g. for buttons actions in bot apps))\n",
        "# It is though extremely useful to be able to serialize the response title to text. \n",
        "# That's what this section content is needed for.\n",
        "responses:\n",
        "  system_utterance_1:\n",
        "    - text: \"The text that system responds with\"\n",
        "  another_system_response:\n",
        "    - text: \"Here some text again\"\n",
        "\n",
        "```\n",
        "\n",
        "**See examples below in this tutorial**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G__SfMVanNGc",
        "colab_type": "text"
      },
      "source": [
        "## Minimal demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAFtnDz4Wbyg",
        "colab_type": "text"
      },
      "source": [
        "Let's build the simplest bot possible.  \n",
        "Let in answer with greeting to greeting and with goodbye to goodbye.\n",
        "And with \"no worries\" to thanks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BElx8chGte5v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DP_MIN_DEMO_DIR = \"dp_minimal_demo_dir\"  # we will work in this folder"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ypZ3rr1ta44",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "26ea6197-a8e7-4195-aada-d6455a0f5986"
      },
      "source": [
        "import os\n",
        "\n",
        "%cd /content\n",
        "os.makedirs(DP_MIN_DEMO_DIR, exist_ok=True)\n",
        "%cd {DP_MIN_DEMO_DIR}"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwJPzxgqWrgf",
        "colab_type": "text"
      },
      "source": [
        "`stories.md` here is pretty straightforward"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsVgqFHxnUFq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0d9f6c8a-e683-4aee-c439-1083b522b649"
      },
      "source": [
        "%%writefile stories.md\n",
        "\n",
        "## greet\n",
        "* greet\n",
        "  - utter_greet\n",
        "\n",
        "## thank\n",
        "* thank\n",
        "  - utter_noworries\n",
        "\n",
        "## goodbye\n",
        "* bye\n",
        "  - utter_bye"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing stories.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oz_qOBjaW2v7",
        "colab_type": "text"
      },
      "source": [
        "`nlu.md` just lists the possible ways to say things :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk1GzeqAuK59",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "153d0fcb-f223-4a54-b9ed-91fb3b6e2ecc"
      },
      "source": [
        "%%writefile nlu.md\n",
        "\n",
        "## intent:greet\n",
        "- Hi\n",
        "- Hey\n",
        "- Hi bot\n",
        "- Hey bot\n",
        "- Hello\n",
        "- Good morning\n",
        "- hi again\n",
        "- hi folks\n",
        "\n",
        "## intent:bye\n",
        "- goodbye\n",
        "- goodnight\n",
        "- good bye\n",
        "- good night\n",
        "- see ya\n",
        "- toodle-oo\n",
        "- bye bye\n",
        "- gotta go\n",
        "- farewell\n",
        "\n",
        "## intent:thank\n",
        "- Thanks\n",
        "- Thank you\n",
        "- Thank you so much\n",
        "- Thanks bot\n",
        "- Thanks for that\n",
        "- cheers\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing nlu.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gt8b1LWTW8mM",
        "colab_type": "text"
      },
      "source": [
        "`domain.yml` lists \n",
        "* the possible user action intents \n",
        "* the possible system response actions\n",
        "\n",
        "Entities and slots are omitted for the moment. See the more sophisticated example below for intuition on them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srHE4tBhvMW4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3af9bb91-cb1f-444a-e577-0ba7a048836a"
      },
      "source": [
        "%%writefile domain.yml\n",
        "\n",
        "intents:\n",
        "  - greet\n",
        "  - bye\n",
        "  - thank\n",
        "\n",
        "responses:\n",
        "  utter_noworries:\n",
        "  - text: No worries!\n",
        "  utter_greet:\n",
        "  - text: Hi\n",
        "  utter_bye:\n",
        "  - text: Bye!"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing domain.yml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75BDcU4yXY1g",
        "colab_type": "text"
      },
      "source": [
        "Let's install the `deeppavlov` library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zcp4-WpCzHaH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "291a0430-b05d-4b8b-8b6e-1f257b455340"
      },
      "source": [
        "!pip install git+https://github.com/deepmipt/DeepPavlov.git@gobot-md-yaml-config-fixes\n",
        "!python -m deeppavlov install gobot_simple_dstc2"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/deepmipt/DeepPavlov.git@gobot-md-yaml-config-fixes\n",
            "  Cloning https://github.com/deepmipt/DeepPavlov.git (to revision gobot-md-yaml-config-fixes) to /tmp/pip-req-build-es08lk40\n",
            "  Running command git clone -q https://github.com/deepmipt/DeepPavlov.git /tmp/pip-req-build-es08lk40\n",
            "  Running command git checkout -b gobot-md-yaml-config-fixes --track origin/gobot-md-yaml-config-fixes\n",
            "  Switched to a new branch 'gobot-md-yaml-config-fixes'\n",
            "  Branch 'gobot-md-yaml-config-fixes' set up to track remote branch 'gobot-md-yaml-config-fixes' from 'origin'.\n",
            "Collecting aio-pika==6.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/07/196a4115cbef31fa0c3dabdea146f02dffe5e49998341d20dbe2278953bc/aio_pika-6.4.1-py3-none-any.whl (40kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.1MB/s \n",
            "\u001b[?25hCollecting Cython==0.29.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/d1/4d3f8a7a920e805488a966cc6ab55c978a712240f584445d703c08b9f405/Cython-0.29.14-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 18.3MB/s \n",
            "\u001b[?25hCollecting fastapi==0.47.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/a7/4804d7abf8a1544d079d50650af872387154ebdac5bd07d54b2e60e2b334/fastapi-0.47.1-py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.6/dist-packages (from deeppavlov==0.11.0) (2.10.0)\n",
            "Collecting nltk==3.4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 42.3MB/s \n",
            "\u001b[?25hCollecting numpy==1.18.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/e6/45f71bd24f4e37629e9db5fb75caab919507deae6a5a257f9e4685a5f931/numpy-1.18.0-cp36-cp36m-manylinux1_x86_64.whl (20.1MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1MB 1.4MB/s \n",
            "\u001b[?25hCollecting overrides==2.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/98/2430afd204c48ac0a529d439d7e22df8fa603c668d03456b5947cb59ec36/overrides-2.7.0.tar.gz\n",
            "Collecting pandas==0.25.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/3f/f6a428599e0d4497e1595030965b5ba455fd8ade6e977e3c819973c4b41d/pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4MB 41.2MB/s \n",
            "\u001b[?25hCollecting pytz==2019.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/73/fe30c2daaaa0713420d0382b16fbb761409f532c56bdcc514bf7b6262bb6/pytz-2019.1-py2.py3-none-any.whl (510kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 39.8MB/s \n",
            "\u001b[?25hCollecting pydantic==1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/24/e78cf017628e7eaed20cb040999b1ecc69f872da53dfd0d9aed40c0fa5f1/pydantic-1.3-cp36-cp36m-manylinux2010_x86_64.whl (7.3MB)\n",
            "\u001b[K     |████████████████████████████████| 7.3MB 19.2MB/s \n",
            "\u001b[?25hCollecting pymorphy2==0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.2MB/s \n",
            "\u001b[?25hCollecting pymorphy2-dicts-ru\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/9b/358faaff410f65a4ad159275e897b5956dcb20576c5b8e764b971c1634d7/pymorphy2_dicts_ru-2.4.404381.4453942-py2.py3-none-any.whl (8.0MB)\n",
            "\u001b[K     |████████████████████████████████| 8.0MB 16.2MB/s \n",
            "\u001b[?25hCollecting pyopenssl==19.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/de/f8342b68fa9e981d348039954657bdf681b2ab93de27443be51865ffa310/pyOpenSSL-19.1.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.7MB/s \n",
            "\u001b[?25hCollecting pytelegrambotapi==3.6.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/ab/99c606f69fcda57e35788b913dd34c9d9acb48dd26349141b3855dcf6351/pyTelegramBotAPI-3.6.7.tar.gz (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.9MB/s \n",
            "\u001b[?25hCollecting requests==2.22.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.8MB/s \n",
            "\u001b[?25hCollecting ruamel.yaml==0.15.100\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/9f/83bb34eaf84032b0b54fcc4a6aff1858572d279d65a301c7ae875f523df5/ruamel.yaml-0.15.100-cp36-cp36m-manylinux1_x86_64.whl (656kB)\n",
            "\u001b[K     |████████████████████████████████| 665kB 39.9MB/s \n",
            "\u001b[?25hCollecting rusenttokenize==0.0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/25/4c/a2f00be5def774a3df2e5387145f1cb54e324607ec4a7e23f573645946e7/rusenttokenize-0.0.5-py3-none-any.whl\n",
            "Collecting scikit-learn==0.21.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/04/49633f490f726da6e454fddc8e938bbb5bfed2001681118d3814c219b723/scikit_learn-0.21.2-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 32.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from deeppavlov==0.11.0) (1.4.1)\n",
            "Requirement already satisfied: tqdm==4.41.1 in /usr/local/lib/python3.6/dist-packages (from deeppavlov==0.11.0) (4.41.1)\n",
            "Requirement already satisfied: click==7.1.2 in /usr/local/lib/python3.6/dist-packages (from deeppavlov==0.11.0) (7.1.2)\n",
            "Collecting uvicorn==0.11.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/24/11f4b4bf3963ead6de570feeae49eeced02f6768cf1f68e16f4b16d3b0aa/uvicorn-0.11.1-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.8MB/s \n",
            "\u001b[?25hCollecting sacremoses==0.0.35\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
            "\u001b[K     |████████████████████████████████| 860kB 36.5MB/s \n",
            "\u001b[?25hCollecting yarl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/9a/2365a077c21c3d711b2367199a81edbe3f362712a05f6437647ca770eab1/yarl-1.5.0-cp36-cp36m-manylinux1_x86_64.whl (257kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 42.0MB/s \n",
            "\u001b[?25hCollecting aiormq<4,>=3.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/6b/c6/4a9f8f22eef268289e9af5da6a620d837c700b333eae01132bfe48fe7dc9/aiormq-3.2.3-py3-none-any.whl\n",
            "Collecting starlette<=0.12.9,>=0.12.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/95/2220fe5bf287e693a6430d8ee36c681b0157035b7249ec08f8fb36319d16/starlette-0.12.9.tar.gz (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py==2.10.0->deeppavlov==0.11.0) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.3->deeppavlov==0.11.0) (2.8.1)\n",
            "Requirement already satisfied: dataclasses>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from pydantic==1.3->deeppavlov==0.11.0) (0.7)\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 23.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2==0.8->deeppavlov==0.11.0) (0.6.2)\n",
            "Collecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Collecting cryptography>=2.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/91/84a29d6a27fd6dfc21f475704c4d2053d58ed7a4033c2b0ce1b4ca4d03d9/cryptography-3.0-cp35-abi3-manylinux2010_x86_64.whl (2.7MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 44.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov==0.11.0) (2020.6.20)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov==0.11.0) (3.0.4)\n",
            "Collecting idna<2.9,>=2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov==0.11.0) (1.24.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21.2->deeppavlov==0.11.0) (0.16.0)\n",
            "Collecting websockets==8.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/d9/856af84843912e2853b1b6e898ac8b802989fcf9ecf8e8445a1da263bf3b/websockets-8.1-cp36-cp36m-manylinux2010_x86_64.whl (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.1MB/s \n",
            "\u001b[?25hCollecting uvloop>=0.14.0; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"pypy\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/48/586225bbb02d3bdca475b17e4be5ce5b3f09da2d6979f359916c1592a687/uvloop-0.14.0-cp36-cp36m-manylinux2010_x86_64.whl (3.9MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 38.5MB/s \n",
            "\u001b[?25hCollecting h11<0.10,>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/fd/3dad730b0f95e78aeeb742f96fa7bbecbdd56a58e405d3da440d5bfb90c6/h11-0.9.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.9MB/s \n",
            "\u001b[?25hCollecting httptools==0.0.13; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"pypy\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/03/215969db11abe8741e9c266a4cbe803a372bd86dd35fa0084c4df6d4bd00/httptools-0.0.13.tar.gz (104kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 45.0MB/s \n",
            "\u001b[?25hCollecting multidict>=4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/95/f50352b5366e7d579e8b99631680a9e32e1b22adfa1629a8f23b1d22d5e2/multidict-4.7.6-cp36-cp36m-manylinux1_x86_64.whl (148kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 43.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.6/dist-packages (from yarl->aio-pika==6.4.1->deeppavlov==0.11.0) (3.7.4.2)\n",
            "Collecting pamqp==2.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/56/afa06143361e640c9159d828dadc95fc9195c52c95b4a97d136617b0166d/pamqp-2.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.8->pyopenssl==19.1.0->deeppavlov==0.11.0) (1.14.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.8->pyopenssl==19.1.0->deeppavlov==0.11.0) (2.20)\n",
            "Building wheels for collected packages: deeppavlov, nltk, overrides, pytelegrambotapi, sacremoses, starlette, httptools\n",
            "  Building wheel for deeppavlov (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deeppavlov: filename=deeppavlov-0.11.0-cp36-none-any.whl size=868656 sha256=5ba351dd4370af6b86c1ceb7805ffd247b208ec9b2acd58a521f4b0d886526b0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gwtzsodx/wheels/4c/4e/02/6f86cd49f80a090c3d4dd23eacbed21b7b2860b73de04dc7e1\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-cp36-none-any.whl size=1449910 sha256=f035d9c5a69019d44970bef27389d02c5a5ed1e5dc1114601e667d051a57d9e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-2.7.0-cp36-none-any.whl size=5600 sha256=f99ce870e76b66207114ef782aec3db6b0fac02ea4c00afbe4ddc28b1d4eee14\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/7c/ef/80508418b67d87371c5b3de49e03eb22ee7c1d19affb5099f8\n",
            "  Building wheel for pytelegrambotapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytelegrambotapi: filename=pyTelegramBotAPI-3.6.7-cp36-none-any.whl size=47178 sha256=3e71a80276b608396bc2795d2b0d9403d275b32d1ac1d74a62954f2fe2a15531\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/40/18/8a34153f95ef0dc19e3954898e5a5079244b76a8afdd7d0ec5\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=005ea62e877b15200a7abe87ee1fa7e316159ac9b8804e208971c53b4647fb43\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
            "  Building wheel for starlette (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for starlette: filename=starlette-0.12.9-cp36-none-any.whl size=57245 sha256=803c4a445198e1b42ee44463a72ff9fea5f152994f07c13de20f35bb6c6f59b9\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/51/5b/3828d52e185cafad941c4291b6f70894d0794be28c70addae5\n",
            "  Building wheel for httptools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for httptools: filename=httptools-0.0.13-cp36-cp36m-linux_x86_64.whl size=212528 sha256=b7c0bf1685c5e53c0fbe81a4e4e1d3247d8381beaeab1f009a963167623e0709\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/3e/2e/013f99b42efc25cf3589730cf380738e46b1e5edaf2f78d525\n",
            "Successfully built deeppavlov nltk overrides pytelegrambotapi sacremoses starlette httptools\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.0.0; python_version >= \"3.0\", but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: multidict, idna, yarl, pamqp, aiormq, aio-pika, Cython, starlette, pydantic, fastapi, nltk, numpy, overrides, pytz, pandas, pymorphy2-dicts, dawg-python, pymorphy2, pymorphy2-dicts-ru, cryptography, pyopenssl, requests, pytelegrambotapi, ruamel.yaml, rusenttokenize, scikit-learn, websockets, uvloop, h11, httptools, uvicorn, sacremoses, deeppavlov\n",
            "  Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Found existing installation: Cython 0.29.21\n",
            "    Uninstalling Cython-0.29.21:\n",
            "      Successfully uninstalled Cython-0.29.21\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "  Found existing installation: pytz 2018.9\n",
            "    Uninstalling pytz-2018.9:\n",
            "      Successfully uninstalled pytz-2018.9\n",
            "  Found existing installation: pandas 1.0.5\n",
            "    Uninstalling pandas-1.0.5:\n",
            "      Successfully uninstalled pandas-1.0.5\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed Cython-0.29.14 aio-pika-6.4.1 aiormq-3.2.3 cryptography-3.0 dawg-python-0.7.2 deeppavlov-0.11.0 fastapi-0.47.1 h11-0.9.0 httptools-0.0.13 idna-2.8 multidict-4.7.6 nltk-3.4.5 numpy-1.18.0 overrides-2.7.0 pamqp-2.3.0 pandas-0.25.3 pydantic-1.3 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985 pymorphy2-dicts-ru-2.4.404381.4453942 pyopenssl-19.1.0 pytelegrambotapi-3.6.7 pytz-2019.1 requests-2.22.0 ruamel.yaml-0.15.100 rusenttokenize-0.0.5 sacremoses-0.0.35 scikit-learn-0.21.2 starlette-0.12.9 uvicorn-0.11.1 uvloop-0.14.0 websockets-8.1 yarl-1.5.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "idna",
                  "numpy",
                  "pandas",
                  "pytz",
                  "requests"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:44:41.851 INFO in 'deeppavlov.core.common.file'['file'] at line 32: Interpreting 'gobot_simple_dstc2' as '/usr/local/lib/python3.6/dist-packages/deeppavlov/configs/go_bot/gobot_simple_dstc2.json'\n",
            "Collecting tensorflow==1.15.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/d9/fd234c7bf68638423fb8e7f44af7fcfce3bcaf416b51e6d902391e47ec43/tensorflow-1.15.2-cp36-cp36m-manylinux2010_x86_64.whl (110.5MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5MB 98kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.9.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.0.8)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 39.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.34.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (3.12.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.1.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (3.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.30.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 38.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.18.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.8.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.2) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.2) (49.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=8c41178fbd0d8ad07b1932ecd1a9f3a607949597d937b5eb86700882281ac439\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, gast, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: tensorboard 2.2.2\n",
            "    Uninstalling tensorboard-2.2.2:\n",
            "      Successfully uninstalled tensorboard-2.2.2\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow 2.2.0\n",
            "    Uninstalling tensorflow-2.2.0:\n",
            "      Successfully uninstalled tensorflow-2.2.0\n",
            "Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-1.15.2 tensorflow-estimator-1.15.1\n",
            "Collecting spacy==2.2.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/13/80ad28ef7a16e2a86d16d73e28588be5f1085afd3e85e4b9b912bd700e8a/spacy-2.2.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4MB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3) (1.18.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3) (49.1.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3) (1.0.2)\n",
            "Collecting thinc<7.4.0,>=7.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/59/6bb553bc9a5f072d3cd479fc939fea0f6f682892f1f5cff98de5c9b615bb/thinc-7.3.1-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 42.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3) (2.22.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3) (2.0.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3) (3.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.3) (0.7.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.4.0,>=7.3.0->spacy==2.2.3) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy==2.2.3) (1.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3) (2020.6.20)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3) (2.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.3) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy==2.2.3) (3.1.0)\n",
            "Installing collected packages: thinc, spacy\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed spacy-2.2.3 thinc-7.3.1\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.22.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (49.1.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.3.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "Collecting gensim==3.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/dd/112bd4258cee11e0baaaba064060eb156475a42362e59e3ff28e7ca2d29d/gensim-3.8.1-cp36-cp36m-manylinux1_x86_64.whl (24.2MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2MB 140kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim==3.8.1) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.6/dist-packages (from gensim==3.8.1) (2.1.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim==3.8.1) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim==3.8.1) (1.18.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim==3.8.1) (1.14.24)\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim==3.8.1) (2.49.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim==3.8.1) (2.22.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim==3.8.1) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.24 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim==3.8.1) (1.17.24)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim==3.8.1) (0.10.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim==3.8.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim==3.8.1) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim==3.8.1) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim==3.8.1) (2.8)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.24->boto3->smart-open>=1.8.1->gensim==3.8.1) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.24->boto3->smart-open>=1.8.1->gensim==3.8.1) (2.8.1)\n",
            "Installing collected packages: gensim\n",
            "  Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-3.8.1\n",
            "Collecting rapidfuzz==0.7.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/4e/66d1ad1ad9f7f1e82c68632a6683c2408cc0e134cebf1a67572370379557/rapidfuzz-0.7.6-cp36-cp36m-manylinux2010_x86_64.whl (689kB)\n",
            "\u001b[K     |████████████████████████████████| 696kB 6.9MB/s \n",
            "\u001b[?25hInstalling collected packages: rapidfuzz\n",
            "Successfully installed rapidfuzz-0.7.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGxtOE-fXiUN",
        "colab_type": "text"
      },
      "source": [
        "Let's specify the path to our dataset (the folder we are in right now) and the folder where to store the trained bot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcC7aDfk6iiM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from deeppavlov import configs\n",
        "from deeppavlov.core.common.file import read_json\n",
        "\n",
        "\n",
        "gobot_config = read_json(configs.go_bot.gobot_md_yaml_minimal)\n",
        "\n",
        "gobot_config['metadata']['variables']['DATA_PATH'] = '.'\n",
        "gobot_config['metadata']['variables']['MODEL_PATH'] = '.'\n",
        "\n",
        "!echo \"{}\" > dstc2-actions2slots.json  # a hack that will be redundant in future versions. keep an empty json file in the data folder"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOenbeUvXwW-",
        "colab_type": "text"
      },
      "source": [
        "Since our data is basically the mock tutorial data we will use the same subsamples for all of train, test and valid subsamples. \n",
        "\n",
        "Our goal here is not the brilliant statistical measures but the working *toy* system. More sophisticated examples will be available soon."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reCVX2Mz7W8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp stories.md stories-trn.md\n",
        "!cp stories.md stories-tst.md \n",
        "!cp stories.md stories-val.md "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjPL3dqzYj3B",
        "colab_type": "text"
      },
      "source": [
        "Let's train the bot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS6hIi9m7Sev",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0e9b2ead-4181-4e71-83dc-65bbdc988b4b"
      },
      "source": [
        "from deeppavlov import train_model\n",
        "\n",
        "train_model(gobot_config, download=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:46:15.31 INFO in 'deeppavlov.core.data.utils'['utils'] at line 94: Downloading from http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt to /root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt\n",
            "347MB [00:16, 20.8MB/s]\n",
            "2020-07-29 10:46:33.314 INFO in 'deeppavlov.core.data.utils'['utils'] at line 94: Downloading from http://files.deeppavlov.ai/datasets/gobot_md_yaml_minimal.tar.gz to /content/gobot_md_yaml_minimal.tar.gz\n",
            "100%|██████████| 472/472 [00:00<00:00, 818kB/s]\n",
            "2020-07-29 10:46:33.417 INFO in 'deeppavlov.core.data.utils'['utils'] at line 269: Extracting /content/gobot_md_yaml_minimal.tar.gz archive into /content/dp_minimal_demo_dir\n",
            "2020-07-29 10:46:33.447 INFO in 'deeppavlov.dataset_readers.md_yaml_dialogs_reader'['md_yaml_dialogs_reader'] at line 123: INSIDE MLU_MD_DialogsDatasetReader._read_domain_knowledge(): reading domain knowledge from /content/dp_minimal_demo_dir/domain.yml\n",
            "2020-07-29 10:46:33.453 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmp0jtxwaq_]\n",
            "2020-07-29 10:46:33.456 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmpjuswaal_]\n",
            "2020-07-29 10:46:33.459 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmpg5qiwbvh]\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data] Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "2020-07-29 10:46:35.311 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /content/dp_minimal_demo_dir/word.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:46:37.520 INFO in 'deeppavlov.dataset_readers.md_yaml_dialogs_reader'['md_yaml_dialogs_reader'] at line 123: INSIDE MLU_MD_DialogsDatasetReader._read_domain_knowledge(): reading domain knowledge from /content/dp_minimal_demo_dir/domain.yml\n",
            "2020-07-29 10:46:37.527 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmpgquo4cpm]\n",
            "2020-07-29 10:46:37.530 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmp9ecfovf6]\n",
            "2020-07-29 10:46:37.533 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmpa1uvr_mo]\n",
            "2020-07-29 10:46:37.654 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/common/registry.py:40: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:194: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/go_bot/policy/policy_network.py:250: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/go_bot/policy/policy_network.py:265: The name tf.nn.rnn_cell.LSTMStateTuple is deprecated. Please use tf.compat.v1.nn.rnn_cell.LSTMStateTuple instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/go_bot/policy/policy_network.py:276: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/go_bot/policy/policy_network.py:285: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/go_bot/policy/policy_network.py:292: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/go_bot/policy/policy_network.py:246: The name tf.losses.get_regularization_loss is deprecated. Please use tf.compat.v1.losses.get_regularization_loss instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:122: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:127: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:127: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py:2825: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/go_bot/policy/policy_network.py:79: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/go_bot/policy/policy_network.py:335: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:47:24.675 INFO in 'deeppavlov.models.go_bot.policy.policy_network'['policy_network'] at line 89: INSIDE PolicyNetwork init(). Initializing PolicyNetwork from scratch.\n",
            "2020-07-29 10:47:24.749 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 198: Initial best per_item_action_accuracy of 0.5\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 0.5}, \"time_spent\": \"0:00:01\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 10}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:47:25.127 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best per_item_action_accuracy of 1.0\n",
            "2020-07-29 10:47:25.128 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 10:47:25.129 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/dp_minimal_demo_dir/model/policy]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:01\", \"epochs_done\": 14, \"batches_seen\": 15, \"train_examples_seen\": 45, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.5606896827618281}}\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:77: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "{\"valid\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:01\", \"epochs_done\": 14, \"batches_seen\": 15, \"train_examples_seen\": 45, \"impatience\": 0, \"patience_limit\": 10}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:47:25.413 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 1.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:01\", \"epochs_done\": 29, \"batches_seen\": 30, \"train_examples_seen\": 90, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.03245726029078166}}\n",
            "{\"valid\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:01\", \"epochs_done\": 29, \"batches_seen\": 30, \"train_examples_seen\": 90, \"impatience\": 1, \"patience_limit\": 10}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:47:25.576 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 1.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:01\", \"epochs_done\": 44, \"batches_seen\": 45, \"train_examples_seen\": 135, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.02362982779741287}}\n",
            "{\"valid\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:01\", \"epochs_done\": 44, \"batches_seen\": 45, \"train_examples_seen\": 135, \"impatience\": 2, \"patience_limit\": 10}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:47:25.741 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 1.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:02\", \"epochs_done\": 59, \"batches_seen\": 60, \"train_examples_seen\": 180, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.022798538332184155}}\n",
            "{\"valid\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:02\", \"epochs_done\": 59, \"batches_seen\": 60, \"train_examples_seen\": 180, \"impatience\": 3, \"patience_limit\": 10}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:47:25.902 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 1.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:02\", \"epochs_done\": 74, \"batches_seen\": 75, \"train_examples_seen\": 225, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.02124113067984581}}\n",
            "{\"valid\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:02\", \"epochs_done\": 74, \"batches_seen\": 75, \"train_examples_seen\": 225, \"impatience\": 4, \"patience_limit\": 10}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:47:26.64 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 1.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:02\", \"epochs_done\": 89, \"batches_seen\": 90, \"train_examples_seen\": 270, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.019369153926769894}}\n",
            "{\"valid\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:02\", \"epochs_done\": 89, \"batches_seen\": 90, \"train_examples_seen\": 270, \"impatience\": 5, \"patience_limit\": 10}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:47:26.223 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 1.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:02\", \"epochs_done\": 104, \"batches_seen\": 105, \"train_examples_seen\": 315, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.017462719852725666}}\n",
            "{\"valid\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:02\", \"epochs_done\": 104, \"batches_seen\": 105, \"train_examples_seen\": 315, \"impatience\": 6, \"patience_limit\": 10}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:47:26.386 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 1.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:02\", \"epochs_done\": 119, \"batches_seen\": 120, \"train_examples_seen\": 360, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.015668151962260405}}\n",
            "{\"valid\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:02\", \"epochs_done\": 119, \"batches_seen\": 120, \"train_examples_seen\": 360, \"impatience\": 7, \"patience_limit\": 10}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:47:26.540 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 1.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:02\", \"epochs_done\": 134, \"batches_seen\": 135, \"train_examples_seen\": 405, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.014041894301772117}}\n",
            "{\"valid\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:02\", \"epochs_done\": 134, \"batches_seen\": 135, \"train_examples_seen\": 405, \"impatience\": 8, \"patience_limit\": 10}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:47:26.699 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 1.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:03\", \"epochs_done\": 149, \"batches_seen\": 150, \"train_examples_seen\": 450, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.012594955538709958}}\n",
            "{\"valid\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:03\", \"epochs_done\": 149, \"batches_seen\": 150, \"train_examples_seen\": 450, \"impatience\": 9, \"patience_limit\": 10}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:47:26.859 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 1.0\n",
            "2020-07-29 10:47:26.860 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 307: Ran out of patience\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:03\", \"epochs_done\": 164, \"batches_seen\": 165, \"train_examples_seen\": 495, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.011319750609497229}}\n",
            "{\"valid\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:03\", \"epochs_done\": 164, \"batches_seen\": 165, \"train_examples_seen\": 495, \"impatience\": 10, \"patience_limit\": 10}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:47:26.945 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/dp_minimal_demo_dir/word.dict]\n",
            "2020-07-29 10:47:26.947 INFO in 'deeppavlov.dataset_readers.md_yaml_dialogs_reader'['md_yaml_dialogs_reader'] at line 123: INSIDE MLU_MD_DialogsDatasetReader._read_domain_knowledge(): reading domain knowledge from /content/dp_minimal_demo_dir/domain.yml\n",
            "2020-07-29 10:47:26.956 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmp5fky1rzn]\n",
            "2020-07-29 10:47:26.962 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmp0w80v1gn]\n",
            "2020-07-29 10:47:26.964 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmp4m624jss]\n",
            "2020-07-29 10:47:26.965 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n",
            "2020-07-29 10:48:11.142 INFO in 'deeppavlov.models.go_bot.policy.policy_network'['policy_network'] at line 86: INSIDE PolicyNetwork init(). Initializing PolicyNetwork from checkpoint.\n",
            "2020-07-29 10:48:11.148 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/dp_minimal_demo_dir/model/policy]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/dp_minimal_demo_dir/model/policy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:48:11.348 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/dp_minimal_demo_dir/word.dict]\n",
            "2020-07-29 10:48:11.351 INFO in 'deeppavlov.dataset_readers.md_yaml_dialogs_reader'['md_yaml_dialogs_reader'] at line 123: INSIDE MLU_MD_DialogsDatasetReader._read_domain_knowledge(): reading domain knowledge from /content/dp_minimal_demo_dir/domain.yml\n",
            "2020-07-29 10:48:11.359 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmp46mip4xp]\n",
            "2020-07-29 10:48:11.363 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmpj8fgl_gg]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:01\"}}\n",
            "{\"test\": {\"eval_examples_count\": 3, \"metrics\": {\"per_item_action_accuracy\": 1.0}, \"time_spent\": \"0:00:01\"}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:48:11.367 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmp4iw165sq]\n",
            "2020-07-29 10:48:11.369 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n",
            "2020-07-29 10:48:55.514 INFO in 'deeppavlov.models.go_bot.policy.policy_network'['policy_network'] at line 86: INSIDE PolicyNetwork init(). Initializing PolicyNetwork from checkpoint.\n",
            "2020-07-29 10:48:55.519 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/dp_minimal_demo_dir/model/policy]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/dp_minimal_demo_dir/model/policy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Chainer[<deeppavlov.models.go_bot.wrapper.DialogComponentWrapper at 0x7ff74f93ca20>,\n",
              "        <deeppavlov.models.go_bot.go_bot.GoalOrientedBot at 0x7ff74de24780>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tenEY1QVYmlg",
        "colab_type": "text"
      },
      "source": [
        "Let's build our bot to play with it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmK7I_06xXcH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "a816b88f-aabb-401a-af35-f5c3d660e7dc"
      },
      "source": [
        "from deeppavlov import build_model\n",
        "bot = build_model(gobot_config)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:48:55.595 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/dp_minimal_demo_dir/word.dict]\n",
            "2020-07-29 10:48:55.598 INFO in 'deeppavlov.dataset_readers.md_yaml_dialogs_reader'['md_yaml_dialogs_reader'] at line 123: INSIDE MLU_MD_DialogsDatasetReader._read_domain_knowledge(): reading domain knowledge from /content/dp_minimal_demo_dir/domain.yml\n",
            "2020-07-29 10:48:55.605 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmpr4_7z4ts]\n",
            "2020-07-29 10:48:55.608 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmphwq8nzhx]\n",
            "2020-07-29 10:48:55.610 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmpy87h0mkq]\n",
            "2020-07-29 10:48:55.613 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n",
            "2020-07-29 10:49:40.615 INFO in 'deeppavlov.models.go_bot.policy.policy_network'['policy_network'] at line 86: INSIDE PolicyNetwork init(). Initializing PolicyNetwork from checkpoint.\n",
            "2020-07-29 10:49:40.624 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/dp_minimal_demo_dir/model/policy]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/dp_minimal_demo_dir/model/policy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2hpK1G0x0gu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "87836728-e3cc-4bd8-94bb-59853b9d974a"
      },
      "source": [
        "bot.reset()\n",
        "\n",
        "bot([\"start\"])\n",
        "bot([\"Hi\"])[0][0].actions_tuple"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('utter_greet',)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbUm-l73Yvry",
        "colab_type": "text"
      },
      "source": [
        "The bot answers with greeting to greeting. What will it respond to some grateful message?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKQ86ESXx9GV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4c8e673f-9db3-4221-b58d-17d2332d95c4"
      },
      "source": [
        "bot.reset()\n",
        "bot([\"start\"])\n",
        "\n",
        "bot([\"Thanks!\"])[0][0].actions_tuple"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('utter_noworries',)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvkEelaEY3kb",
        "colab_type": "text"
      },
      "source": [
        "Ok, no woories is an expected response. And with goodbye message, let's see some textual answer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aM9xCLMs5Ke5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bot.reset()\n",
        "bot([\"start\"])\n",
        "\n",
        "bot_response_actions = bot([\"bye\"])[0][0].actions_tuple"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhqKmwbO6K1v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "325be164-6be5-441b-b636-3f93013e86f7"
      },
      "source": [
        "import yaml\n",
        "\n",
        "system_utter2text = yaml.load(open(\"domain.yml\"))[\"responses\"]\n",
        "system_utter2text[bot_response_actions[0]][0][\"text\"]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Bye!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJUFlCjinRsP",
        "colab_type": "text"
      },
      "source": [
        "## Not that minimal demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Yf5iQC1nh7d",
        "colab_type": "text"
      },
      "source": [
        "Now let's take the [Schema](asdf) dataset.\n",
        "We naively converted most of *Restaurants 1* dialogues from Schema to the md+yml format to keep things simple. \n",
        "\n",
        "These are the annotated dialogs on the restaurant tables booking domain.\n",
        "We will not involve the DB usage in our example and the bot should just learn to respond with relevant actions to user's utterances.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilk5KxbBi98e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DP_BIG_DEMO_DIR = \"dp_big_demo_dir\"  # we'll work in this directory"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqCEXGyEjDrQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "382a72f3-5a51-4538-a7a2-1f322562163b"
      },
      "source": [
        "import os\n",
        "\n",
        "%cd /content\n",
        "os.makedirs(DP_BIG_DEMO_DIR, exist_ok=True)\n",
        "%cd {DP_BIG_DEMO_DIR}"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/dp_big_demo_dir\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XcO1oe7nw7G",
        "colab_type": "text"
      },
      "source": [
        "download the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSgoo2CSk0Ku",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "14d3e340-6e07-4e66-8832-aa2393cfb1aa"
      },
      "source": [
        "# let's get the mentioned converted Schema-dataset subset\n",
        "!wget http://files.deeppavlov.ai/datasets/schema_resto_md_yaml.tar.gz\n",
        "!tar -zxf schema_resto_md_yaml.tar.gz "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-29 10:49:41--  http://files.deeppavlov.ai/datasets/schema_resto_md_yaml.tar.gz\n",
            "Resolving files.deeppavlov.ai (files.deeppavlov.ai)... 93.175.29.74\n",
            "Connecting to files.deeppavlov.ai (files.deeppavlov.ai)|93.175.29.74|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 98718 (96K) [application/octet-stream]\n",
            "Saving to: ‘schema_resto_md_yaml.tar.gz’\n",
            "\n",
            "\r          schema_re   0%[                    ]       0  --.-KB/s               \rschema_resto_md_yam 100%[===================>]  96.40K  --.-KB/s    in 0.09s   \n",
            "\n",
            "2020-07-29 10:49:42 (1.10 MB/s) - ‘schema_resto_md_yaml.tar.gz’ saved [98718/98718]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kf2Tm6RbZwOx",
        "colab_type": "text"
      },
      "source": [
        "First of all let's train the NER model that will be used by bot. No .md or .yml configs illustrated here, but the trained model is inevitable part of the go-bot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX9yLwjoltDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from deeppavlov import configs, train_model\n",
        "from deeppavlov.core.common.file import read_json\n",
        "\n",
        "ner_config = read_json(configs.ner.ner_conll2003)\n",
        "ner_config[\"dataset_reader\"] = read_json(configs.ner.ner_few_shot_ru)[\"dataset_reader\"]\n",
        "ner_config[\"dataset_reader\"][\"data_path\"] = \"schema_resto_md_yaml/ner\""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lAcp-Rxm-IX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "fd370e41-4379-4bf3-e5ef-7698d3508e65"
      },
      "source": [
        "!python -m deeppavlov download ner_conll2003\n",
        "!rm -r /root/.deeppavlov/models/ner_conll2003  # remove cached models if present"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:49:46.783 INFO in 'deeppavlov.core.common.file'['file'] at line 32: Interpreting 'ner_conll2003' as '/usr/local/lib/python3.6/dist-packages/deeppavlov/configs/ner/ner_conll2003.json'\n",
            "2020-07-29 10:49:47.873 INFO in 'deeppavlov.download'['download'] at line 132: Skipped http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt?config=ner_conll2003 download because of matching hashes\n",
            "2020-07-29 10:49:47.963 INFO in 'deeppavlov.core.data.utils'['utils'] at line 94: Downloading from http://files.deeppavlov.ai/deeppavlov_data/ner_conll2003_v5.tar.gz?config=ner_conll2003 to /root/.deeppavlov/ner_conll2003_v5.tar.gz\n",
            "100% 3.12M/3.12M [00:00<00:00, 3.81MB/s]\n",
            "2020-07-29 10:49:48.874 INFO in 'deeppavlov.core.data.utils'['utils'] at line 269: Extracting /root/.deeppavlov/ner_conll2003_v5.tar.gz archive into /root/.deeppavlov/models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXaU3YlNbS2f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "785731c0-182b-405a-f53a-819b39488a1f"
      },
      "source": [
        "# if rm says that these files are missing that's ok \n",
        "#   (we just deleted the whole folder containing these paths ^__^)\n",
        "# but if they're present we should delete them \n",
        "# cause they're checkpoints of some other model\n",
        "!rm /root/.deeppavlov/models/ner_conll2003/{checkpoint,model_no_pos}*"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/root/.deeppavlov/models/ner_conll2003/checkpoint*': No such file or directory\n",
            "rm: cannot remove '/root/.deeppavlov/models/ner_conll2003/model_no_pos*': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ui1hyjUxbU6g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a3ea9697-cb56-413a-bc0b-c4a84e534f75"
      },
      "source": [
        "ner_model = train_model(ner_config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:49:53.173 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /root/.deeppavlov/models/ner_conll2003/word.dict]\n",
            "2020-07-29 10:49:53.182 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /root/.deeppavlov/models/ner_conll2003/tag.dict]\n",
            "2020-07-29 10:49:53.204 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /root/.deeppavlov/models/ner_conll2003/char.dict]\n",
            "2020-07-29 10:49:53.208 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/ner/network.py:96: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/layers/tf_layers.py:420: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/ner/network.py:211: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/common/check_gpu.py:29: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:50:36.584 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 760: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/layers/tf_layers.py:733: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/layers/tf_layers.py:865: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "seq_dim is deprecated, use seq_axis instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py:507: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "batch_dim is deprecated, use batch_axis instead\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:50:36.699 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 760: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2020-07-29 10:50:39.516 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 1152 phrases; correct: 0.\n",
            "\n",
            "precision:  0.61%; recall:  21.88%; FB1:  1.18\n",
            "\n",
            "\tcity: precision:  0.00%; recall:  0.00%; F1:  0.00 3\n",
            "\n",
            "\tcuisine: precision:  2.29%; recall:  46.15%; F1:  4.36 262\n",
            "\n",
            "\tdate: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
            "\n",
            "\tprice_range: precision:  0.00%; recall:  0.00%; F1:  0.00 271\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 382\n",
            "\n",
            "\ttime: precision:  0.43%; recall:  33.33%; F1:  0.85 233\n",
            "\n",
            "\n",
            "2020-07-29 10:50:39.521 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 198: Initial best ner_f1 of 1.1824\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 1.1824, \"ner_token_f1\": 3.4682}, \"time_spent\": \"0:00:01\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:50:44.51 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 441 tokens with 13 phrases; found: 5 phrases; correct: 0.\n",
            "\n",
            "precision:  20.00%; recall:  7.69%; FB1:  11.11\n",
            "\n",
            "\tcity: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\tcuisine: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\tprice_range: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  20.00%; recall:  20.00%; F1:  20.00 5\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 11.1111, \"ner_token_f1\": 31.25}, \"time_spent\": \"0:00:05\", \"epochs_done\": 1, \"batches_seen\": 14, \"train_examples_seen\": 854, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 3.5872675478458405}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:50:44.369 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 3 phrases; correct: 0.\n",
            "\n",
            "precision:  33.33%; recall:  3.12%; FB1:  5.71\n",
            "\n",
            "\tcity: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\tcuisine: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\tdate: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\tprice_range: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  33.33%; recall:  33.33%; F1:  33.33 3\n",
            "\n",
            "\n",
            "2020-07-29 10:50:44.372 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 5.7143\n",
            "2020-07-29 10:50:44.375 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 10:50:44.377 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 5.7143, \"ner_token_f1\": 7.4074}, \"time_spent\": \"0:00:06\", \"epochs_done\": 1, \"batches_seen\": 14, \"train_examples_seen\": 854, \"impatience\": 0, \"patience_limit\": 7}}\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:211: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:50:48.595 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 400 tokens with 12 phrases; found: 6 phrases; correct: 0.\n",
            "\n",
            "precision:  83.33%; recall:  41.67%; FB1:  55.56\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  33.33%; F1:  50.00 1\n",
            "\n",
            "\tcuisine: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\tprice_range: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  80.00%; recall:  100.00%; F1:  88.89 5\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 55.5556, \"ner_token_f1\": 57.1429}, \"time_spent\": \"0:00:10\", \"epochs_done\": 2, \"batches_seen\": 28, \"train_examples_seen\": 1708, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 1.1525483599730901}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:50:48.913 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 10 phrases; correct: 0.\n",
            "\n",
            "precision:  20.00%; recall:  6.25%; FB1:  9.52\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  12.50%; F1:  22.22 1\n",
            "\n",
            "\tcuisine: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
            "\n",
            "\tdate: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\tprice_range: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  12.50%; recall:  33.33%; F1:  18.18 8\n",
            "\n",
            "\n",
            "2020-07-29 10:50:48.917 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 9.5238\n",
            "2020-07-29 10:50:48.919 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 10:50:48.921 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 9.5238, \"ner_token_f1\": 22.2222}, \"time_spent\": \"0:00:10\", \"epochs_done\": 2, \"batches_seen\": 28, \"train_examples_seen\": 1708, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:50:53.152 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 409 tokens with 6 phrases; found: 3 phrases; correct: 0.\n",
            "\n",
            "precision:  100.00%; recall:  50.00%; FB1:  66.67\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  50.00%; F1:  66.67 1\n",
            "\n",
            "\tprice_range: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 66.6667, \"ner_token_f1\": 66.6667}, \"time_spent\": \"0:00:15\", \"epochs_done\": 3, \"batches_seen\": 42, \"train_examples_seen\": 2562, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.6782802854265485}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:50:53.460 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 23 phrases; correct: 0.\n",
            "\n",
            "precision:  30.43%; recall:  21.88%; FB1:  25.45\n",
            "\n",
            "\tcity: precision:  50.00%; recall:  50.00%; F1:  50.00 8\n",
            "\n",
            "\tcuisine: precision:  10.00%; recall:  7.69%; F1:  8.70 10\n",
            "\n",
            "\tdate: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\tprice_range: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  40.00%; recall:  66.67%; F1:  50.00 5\n",
            "\n",
            "\n",
            "2020-07-29 10:50:53.464 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 25.4545\n",
            "2020-07-29 10:50:53.466 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 10:50:53.469 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 25.4545, \"ner_token_f1\": 55.6962}, \"time_spent\": \"0:00:15\", \"epochs_done\": 3, \"batches_seen\": 42, \"train_examples_seen\": 2562, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:50:57.644 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 503 tokens with 10 phrases; found: 10 phrases; correct: 0.\n",
            "\n",
            "precision:  90.00%; recall:  90.00%; FB1:  90.00\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\ttime: precision:  75.00%; recall:  75.00%; F1:  75.00 4\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 90.0, \"ner_token_f1\": 96.7742}, \"time_spent\": \"0:00:19\", \"epochs_done\": 4, \"batches_seen\": 56, \"train_examples_seen\": 3416, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.40842629596590996}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:50:57.965 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 27 phrases; correct: 0.\n",
            "\n",
            "precision:  51.85%; recall:  43.75%; FB1:  47.46\n",
            "\n",
            "\tcity: precision:  77.78%; recall:  87.50%; F1:  82.35 9\n",
            "\n",
            "\tcuisine: precision:  28.57%; recall:  30.77%; F1:  29.63 14\n",
            "\n",
            "\tdate: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\tprice_range: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  75.00%; recall:  100.00%; F1:  85.71 4\n",
            "\n",
            "\n",
            "2020-07-29 10:50:57.969 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 47.4576\n",
            "2020-07-29 10:50:57.972 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 10:50:57.975 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 47.4576, \"ner_token_f1\": 75.0}, \"time_spent\": \"0:00:19\", \"epochs_done\": 4, \"batches_seen\": 56, \"train_examples_seen\": 3416, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:51:02.183 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 373 tokens with 11 phrases; found: 11 phrases; correct: 0.\n",
            "\n",
            "precision:  72.73%; recall:  72.73%; FB1:  72.73\n",
            "\n",
            "\tcity: precision:  33.33%; recall:  50.00%; F1:  40.00 3\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\tdate: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
            "\n",
            "\tprice_range: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 72.7273, \"ner_token_f1\": 93.3333}, \"time_spent\": \"0:00:24\", \"epochs_done\": 5, \"batches_seen\": 70, \"train_examples_seen\": 4270, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.27440142897622927}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:51:02.501 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 38 phrases; correct: 0.\n",
            "\n",
            "precision:  42.11%; recall:  50.00%; FB1:  45.71\n",
            "\n",
            "\tcity: precision:  60.00%; recall:  75.00%; F1:  66.67 10\n",
            "\n",
            "\tcuisine: precision:  30.43%; recall:  53.85%; F1:  38.89 23\n",
            "\n",
            "\tdate: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\tprice_range: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  60.00%; recall:  100.00%; F1:  75.00 5\n",
            "\n",
            "\n",
            "2020-07-29 10:51:02.505 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 47.4576\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 45.7143, \"ner_token_f1\": 77.551}, \"time_spent\": \"0:00:24\", \"epochs_done\": 5, \"batches_seen\": 70, \"train_examples_seen\": 4270, \"impatience\": 1, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:51:06.317 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 457 tokens with 8 phrases; found: 9 phrases; correct: 0.\n",
            "\n",
            "precision:  77.78%; recall:  87.50%; FB1:  82.35\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tcuisine: precision:  33.33%; recall:  100.00%; F1:  50.00 3\n",
            "\n",
            "\tprice_range: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\trestaurant_name: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 82.3529, \"ner_token_f1\": 89.6552}, \"time_spent\": \"0:00:28\", \"epochs_done\": 6, \"batches_seen\": 84, \"train_examples_seen\": 5124, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.16375439999891178}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:51:06.629 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 40 phrases; correct: 0.\n",
            "\n",
            "precision:  50.00%; recall:  62.50%; FB1:  55.56\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 8\n",
            "\n",
            "\tcuisine: precision:  32.00%; recall:  61.54%; F1:  42.11 25\n",
            "\n",
            "\tdate: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  25.00%; F1:  40.00 1\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  60.00%; recall:  100.00%; F1:  75.00 5\n",
            "\n",
            "\n",
            "2020-07-29 10:51:06.632 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 55.5556\n",
            "2020-07-29 10:51:06.634 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 10:51:06.640 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 55.5556, \"ner_token_f1\": 82.3529}, \"time_spent\": \"0:00:28\", \"epochs_done\": 6, \"batches_seen\": 84, \"train_examples_seen\": 5124, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:51:10.841 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 376 tokens with 8 phrases; found: 9 phrases; correct: 0.\n",
            "\n",
            "precision:  77.78%; recall:  87.50%; FB1:  82.35\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 2\n",
            "\n",
            "\tcuisine: precision:  50.00%; recall:  66.67%; F1:  57.14 4\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 2\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 82.3529, \"ner_token_f1\": 100.0}, \"time_spent\": \"0:00:32\", \"epochs_done\": 7, \"batches_seen\": 98, \"train_examples_seen\": 5978, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.11639340966939926}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:51:11.159 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 39 phrases; correct: 0.\n",
            "\n",
            "precision:  58.97%; recall:  71.88%; FB1:  64.79\n",
            "\n",
            "\tcity: precision:  77.78%; recall:  87.50%; F1:  82.35 9\n",
            "\n",
            "\tcuisine: precision:  42.86%; recall:  69.23%; F1:  52.94 21\n",
            "\n",
            "\tdate: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  75.00%; recall:  100.00%; F1:  85.71 4\n",
            "\n",
            "\n",
            "2020-07-29 10:51:11.162 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 64.7887\n",
            "2020-07-29 10:51:11.164 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 10:51:11.166 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 64.7887, \"ner_token_f1\": 89.1089}, \"time_spent\": \"0:00:33\", \"epochs_done\": 7, \"batches_seen\": 98, \"train_examples_seen\": 5978, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:51:15.287 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 399 tokens with 16 phrases; found: 18 phrases; correct: 0.\n",
            "\n",
            "precision:  77.78%; recall:  87.50%; FB1:  82.35\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 2\n",
            "\n",
            "\tcuisine: precision:  50.00%; recall:  66.67%; F1:  57.14 8\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 6\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 82.3529, \"ner_token_f1\": 100.0}, \"time_spent\": \"0:00:37\", \"epochs_done\": 8, \"batches_seen\": 112, \"train_examples_seen\": 6832, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.0872481574437448}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:51:15.597 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 37 phrases; correct: 0.\n",
            "\n",
            "precision:  67.57%; recall:  78.12%; FB1:  72.46\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 8\n",
            "\n",
            "\tcuisine: precision:  42.86%; recall:  69.23%; F1:  52.94 21\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\n",
            "2020-07-29 10:51:15.602 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 72.4638\n",
            "2020-07-29 10:51:15.604 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 10:51:15.606 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 72.4638, \"ner_token_f1\": 89.1089}, \"time_spent\": \"0:00:37\", \"epochs_done\": 8, \"batches_seen\": 112, \"train_examples_seen\": 6832, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:51:19.909 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 432 tokens with 8 phrases; found: 8 phrases; correct: 0.\n",
            "\n",
            "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  100.00%; F1:  100.00 2\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"ner_token_f1\": 100.0}, \"time_spent\": \"0:00:41\", \"epochs_done\": 9, \"batches_seen\": 126, \"train_examples_seen\": 7686, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.07007527843649898}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:51:20.216 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 35 phrases; correct: 0.\n",
            "\n",
            "precision:  77.14%; recall:  84.38%; FB1:  80.60\n",
            "\n",
            "\tcity: precision:  88.89%; recall:  100.00%; F1:  94.12 9\n",
            "\n",
            "\tcuisine: precision:  64.71%; recall:  84.62%; F1:  73.33 17\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  75.00%; recall:  100.00%; F1:  85.71 4\n",
            "\n",
            "\n",
            "2020-07-29 10:51:20.224 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 80.597\n",
            "2020-07-29 10:51:20.225 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 10:51:20.227 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 80.597, \"ner_token_f1\": 90.1961}, \"time_spent\": \"0:00:42\", \"epochs_done\": 9, \"batches_seen\": 126, \"train_examples_seen\": 7686, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:51:24.458 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 408 tokens with 19 phrases; found: 19 phrases; correct: 0.\n",
            "\n",
            "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 5\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\trestaurant_name: precision:  100.00%; recall:  100.00%; F1:  100.00 2\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 6\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"ner_token_f1\": 100.0}, \"time_spent\": \"0:00:46\", \"epochs_done\": 10, \"batches_seen\": 140, \"train_examples_seen\": 8540, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.0534006249300936}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:51:24.774 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 33 phrases; correct: 0.\n",
            "\n",
            "precision:  81.82%; recall:  84.38%; FB1:  83.08\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 8\n",
            "\n",
            "\tcuisine: precision:  64.71%; recall:  84.62%; F1:  73.33 17\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\n",
            "2020-07-29 10:51:24.778 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 83.0769\n",
            "2020-07-29 10:51:24.779 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 10:51:24.782 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 83.0769, \"ner_token_f1\": 92.0}, \"time_spent\": \"0:00:46\", \"epochs_done\": 10, \"batches_seen\": 140, \"train_examples_seen\": 8540, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:51:29.70 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 485 tokens with 10 phrases; found: 10 phrases; correct: 0.\n",
            "\n",
            "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 2\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  100.00%; F1:  100.00 5\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 2\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"ner_token_f1\": 100.0}, \"time_spent\": \"0:00:50\", \"epochs_done\": 11, \"batches_seen\": 154, \"train_examples_seen\": 9394, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.04254576690228922}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:51:29.438 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 35 phrases; correct: 0.\n",
            "\n",
            "precision:  71.43%; recall:  78.12%; FB1:  74.63\n",
            "\n",
            "\tcity: precision:  87.50%; recall:  87.50%; F1:  87.50 8\n",
            "\n",
            "\tcuisine: precision:  52.63%; recall:  76.92%; F1:  62.50 19\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\n",
            "2020-07-29 10:51:29.444 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 83.0769\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 74.6269, \"ner_token_f1\": 90.0}, \"time_spent\": \"0:00:51\", \"epochs_done\": 11, \"batches_seen\": 154, \"train_examples_seen\": 9394, \"impatience\": 1, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:51:33.397 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 427 tokens with 16 phrases; found: 16 phrases; correct: 0.\n",
            "\n",
            "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 5\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"ner_token_f1\": 100.0}, \"time_spent\": \"0:00:55\", \"epochs_done\": 12, \"batches_seen\": 168, \"train_examples_seen\": 10248, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.028873987246437798}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:51:33.713 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 34 phrases; correct: 0.\n",
            "\n",
            "precision:  85.29%; recall:  90.62%; FB1:  87.88\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 8\n",
            "\n",
            "\tcuisine: precision:  72.22%; recall:  100.00%; F1:  83.87 18\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\n",
            "2020-07-29 10:51:33.716 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 87.8788\n",
            "2020-07-29 10:51:33.718 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 10:51:33.724 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 87.8788, \"ner_token_f1\": 89.3204}, \"time_spent\": \"0:00:55\", \"epochs_done\": 12, \"batches_seen\": 168, \"train_examples_seen\": 10248, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:51:37.918 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 412 tokens with 9 phrases; found: 9 phrases; correct: 0.\n",
            "\n",
            "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\trestaurant_name: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 5\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"ner_token_f1\": 100.0}, \"time_spent\": \"0:00:59\", \"epochs_done\": 13, \"batches_seen\": 182, \"train_examples_seen\": 11102, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.012544907726156193}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:51:38.240 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 32 phrases; correct: 0.\n",
            "\n",
            "precision:  71.88%; recall:  71.88%; FB1:  71.88\n",
            "\n",
            "\tcity: precision:  87.50%; recall:  87.50%; F1:  87.50 8\n",
            "\n",
            "\tcuisine: precision:  50.00%; recall:  61.54%; F1:  55.17 16\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\n",
            "2020-07-29 10:51:38.246 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 87.8788\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 71.875, \"ner_token_f1\": 87.5}, \"time_spent\": \"0:01:00\", \"epochs_done\": 13, \"batches_seen\": 182, \"train_examples_seen\": 11102, \"impatience\": 1, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:51:42.263 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 339 tokens with 11 phrases; found: 11 phrases; correct: 0.\n",
            "\n",
            "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"ner_token_f1\": 100.0}, \"time_spent\": \"0:01:04\", \"epochs_done\": 14, \"batches_seen\": 196, \"train_examples_seen\": 11956, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.028337876977665082}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:51:42.578 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 35 phrases; correct: 0.\n",
            "\n",
            "precision:  74.29%; recall:  81.25%; FB1:  77.61\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 8\n",
            "\n",
            "\tcuisine: precision:  52.63%; recall:  76.92%; F1:  62.50 19\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\n",
            "2020-07-29 10:51:42.582 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 87.8788\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 77.6119, \"ner_token_f1\": 91.0891}, \"time_spent\": \"0:01:04\", \"epochs_done\": 14, \"batches_seen\": 196, \"train_examples_seen\": 11956, \"impatience\": 2, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:51:46.641 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 459 tokens with 11 phrases; found: 11 phrases; correct: 0.\n",
            "\n",
            "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\trestaurant_name: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"ner_token_f1\": 100.0}, \"time_spent\": \"0:01:08\", \"epochs_done\": 15, \"batches_seen\": 210, \"train_examples_seen\": 12810, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.01742572443825858}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:51:46.965 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 34 phrases; correct: 0.\n",
            "\n",
            "precision:  79.41%; recall:  84.38%; FB1:  81.82\n",
            "\n",
            "\tcity: precision:  88.89%; recall:  100.00%; F1:  94.12 9\n",
            "\n",
            "\tcuisine: precision:  73.33%; recall:  84.62%; F1:  78.57 15\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
            "\n",
            "\ttime: precision:  75.00%; recall:  100.00%; F1:  85.71 4\n",
            "\n",
            "\n",
            "2020-07-29 10:51:46.968 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 87.8788\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 81.8182, \"ner_token_f1\": 88.2353}, \"time_spent\": \"0:01:08\", \"epochs_done\": 15, \"batches_seen\": 210, \"train_examples_seen\": 12810, \"impatience\": 3, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:51:50.927 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 399 tokens with 9 phrases; found: 9 phrases; correct: 0.\n",
            "\n",
            "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 2\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  100.00%; F1:  100.00 2\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"ner_token_f1\": 100.0}, \"time_spent\": \"0:01:12\", \"epochs_done\": 16, \"batches_seen\": 224, \"train_examples_seen\": 13664, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.017270211321634373}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:51:51.233 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 36 phrases; correct: 0.\n",
            "\n",
            "precision:  72.22%; recall:  81.25%; FB1:  76.47\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  87.50%; F1:  93.33 7\n",
            "\n",
            "\tcuisine: precision:  63.16%; recall:  92.31%; F1:  75.00 19\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  40.00%; recall:  66.67%; F1:  50.00 5\n",
            "\n",
            "\n",
            "2020-07-29 10:51:51.237 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 87.8788\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 76.4706, \"ner_token_f1\": 84.0}, \"time_spent\": \"0:01:13\", \"epochs_done\": 16, \"batches_seen\": 224, \"train_examples_seen\": 13664, \"impatience\": 4, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:51:54.977 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 509 tokens with 16 phrases; found: 16 phrases; correct: 0.\n",
            "\n",
            "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 7\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\trestaurant_name: precision:  100.00%; recall:  100.00%; F1:  100.00 2\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 2\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"ner_token_f1\": 100.0}, \"time_spent\": \"0:01:16\", \"epochs_done\": 17, \"batches_seen\": 238, \"train_examples_seen\": 14518, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.01024019911086985}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:51:55.285 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 33 phrases; correct: 0.\n",
            "\n",
            "precision:  87.88%; recall:  90.62%; FB1:  89.23\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 8\n",
            "\n",
            "\tcuisine: precision:  81.25%; recall:  100.00%; F1:  89.66 16\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\n",
            "2020-07-29 10:51:55.288 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 of 89.2308\n",
            "2020-07-29 10:51:55.290 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 10:51:55.293 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 89.2308, \"ner_token_f1\": 90.1961}, \"time_spent\": \"0:01:17\", \"epochs_done\": 17, \"batches_seen\": 238, \"train_examples_seen\": 14518, \"impatience\": 0, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:51:59.534 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 417 tokens with 9 phrases; found: 9 phrases; correct: 0.\n",
            "\n",
            "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"ner_token_f1\": 100.0}, \"time_spent\": \"0:01:21\", \"epochs_done\": 18, \"batches_seen\": 252, \"train_examples_seen\": 15372, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.010639990214258432}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:51:59.854 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 35 phrases; correct: 0.\n",
            "\n",
            "precision:  71.43%; recall:  78.12%; FB1:  74.63\n",
            "\n",
            "\tcity: precision:  87.50%; recall:  87.50%; F1:  87.50 8\n",
            "\n",
            "\tcuisine: precision:  52.63%; recall:  76.92%; F1:  62.50 19\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\n",
            "2020-07-29 10:51:59.861 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 89.2308\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 74.6269, \"ner_token_f1\": 88.8889}, \"time_spent\": \"0:01:21\", \"epochs_done\": 18, \"batches_seen\": 252, \"train_examples_seen\": 15372, \"impatience\": 1, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:52:03.819 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 479 tokens with 15 phrases; found: 15 phrases; correct: 0.\n",
            "\n",
            "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 2\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\trestaurant_name: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 7\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"ner_token_f1\": 100.0}, \"time_spent\": \"0:01:25\", \"epochs_done\": 19, \"batches_seen\": 266, \"train_examples_seen\": 16226, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.01147097823351422}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:52:04.141 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 35 phrases; correct: 0.\n",
            "\n",
            "precision:  71.43%; recall:  78.12%; FB1:  74.63\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  87.50%; F1:  93.33 7\n",
            "\n",
            "\tcuisine: precision:  52.63%; recall:  76.92%; F1:  62.50 19\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\n",
            "2020-07-29 10:52:04.145 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 89.2308\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 74.6269, \"ner_token_f1\": 88.0}, \"time_spent\": \"0:01:26\", \"epochs_done\": 19, \"batches_seen\": 266, \"train_examples_seen\": 16226, \"impatience\": 2, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:52:08.152 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 472 tokens with 15 phrases; found: 15 phrases; correct: 0.\n",
            "\n",
            "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 6\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\trestaurant_name: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 6\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"ner_token_f1\": 100.0}, \"time_spent\": \"0:01:30\", \"epochs_done\": 20, \"batches_seen\": 280, \"train_examples_seen\": 17080, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.021408442457738732}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:52:08.462 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 36 phrases; correct: 0.\n",
            "\n",
            "precision:  72.22%; recall:  81.25%; FB1:  76.47\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 8\n",
            "\n",
            "\tcuisine: precision:  52.63%; recall:  76.92%; F1:  62.50 19\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\n",
            "2020-07-29 10:52:08.465 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 89.2308\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 76.4706, \"ner_token_f1\": 90.1961}, \"time_spent\": \"0:01:30\", \"epochs_done\": 20, \"batches_seen\": 280, \"train_examples_seen\": 17080, \"impatience\": 3, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:52:12.533 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 405 tokens with 10 phrases; found: 10 phrases; correct: 0.\n",
            "\n",
            "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  100.00%; F1:  100.00 2\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 7\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"ner_token_f1\": 100.0}, \"time_spent\": \"0:01:34\", \"epochs_done\": 21, \"batches_seen\": 294, \"train_examples_seen\": 17934, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.01952673393368189}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:52:12.861 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 38 phrases; correct: 0.\n",
            "\n",
            "precision:  63.16%; recall:  75.00%; FB1:  68.57\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  87.50%; F1:  93.33 7\n",
            "\n",
            "\tcuisine: precision:  45.45%; recall:  76.92%; F1:  57.14 22\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  50.00%; recall:  66.67%; F1:  57.14 4\n",
            "\n",
            "\n",
            "2020-07-29 10:52:12.865 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 89.2308\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 68.5714, \"ner_token_f1\": 86.0}, \"time_spent\": \"0:01:34\", \"epochs_done\": 21, \"batches_seen\": 294, \"train_examples_seen\": 17934, \"impatience\": 4, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:52:16.693 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 468 tokens with 10 phrases; found: 10 phrases; correct: 0.\n",
            "\n",
            "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 2\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"ner_token_f1\": 100.0}, \"time_spent\": \"0:01:38\", \"epochs_done\": 22, \"batches_seen\": 308, \"train_examples_seen\": 18788, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.024231716192194393}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:52:17.20 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 36 phrases; correct: 0.\n",
            "\n",
            "precision:  69.44%; recall:  78.12%; FB1:  73.53\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  87.50%; F1:  93.33 7\n",
            "\n",
            "\tcuisine: precision:  47.62%; recall:  76.92%; F1:  58.82 21\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\n",
            "2020-07-29 10:52:17.25 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 89.2308\n",
            "2020-07-29 10:52:17.131 INFO in 'deeppavlov.core.models.lr_scheduled_model'['lr_scheduled_model'] at line 429: New learning rate dividor = 10.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 73.5294, \"ner_token_f1\": 87.1287}, \"time_spent\": \"0:01:38\", \"epochs_done\": 22, \"batches_seen\": 308, \"train_examples_seen\": 18788, \"impatience\": 5, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:52:21.153 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 455 tokens with 15 phrases; found: 15 phrases; correct: 0.\n",
            "\n",
            "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 2\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  100.00%; F1:  100.00 6\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\trestaurant_name: precision:  100.00%; recall:  100.00%; F1:  100.00 2\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"ner_token_f1\": 100.0}, \"time_spent\": \"0:01:43\", \"epochs_done\": 23, \"batches_seen\": 322, \"train_examples_seen\": 19642, \"learning_rate\": 0.001, \"momentum\": null, \"loss\": 0.008262871777073346}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:52:21.473 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 33 phrases; correct: 0.\n",
            "\n",
            "precision:  81.82%; recall:  84.38%; FB1:  83.08\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  87.50%; F1:  93.33 7\n",
            "\n",
            "\tcuisine: precision:  66.67%; recall:  92.31%; F1:  77.42 18\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\n",
            "2020-07-29 10:52:21.478 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 89.2308\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 83.0769, \"ner_token_f1\": 88.0}, \"time_spent\": \"0:01:43\", \"epochs_done\": 23, \"batches_seen\": 322, \"train_examples_seen\": 19642, \"impatience\": 6, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:52:25.317 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 382 tokens with 9 phrases; found: 9 phrases; correct: 0.\n",
            "\n",
            "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\tcuisine: precision:  100.00%; recall:  100.00%; F1:  100.00 2\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 2\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"ner_token_f1\": 100.0}, \"time_spent\": \"0:01:47\", \"epochs_done\": 24, \"batches_seen\": 336, \"train_examples_seen\": 20496, \"learning_rate\": 0.001, \"momentum\": null, \"loss\": 0.005426280442666861}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:52:25.634 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 32 phrases; correct: 0.\n",
            "\n",
            "precision:  87.50%; recall:  87.50%; FB1:  87.50\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  87.50%; F1:  93.33 7\n",
            "\n",
            "\tcuisine: precision:  76.47%; recall:  100.00%; F1:  86.67 17\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\n",
            "2020-07-29 10:52:25.638 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 89.2308\n",
            "2020-07-29 10:52:25.753 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 328: Ran out of patience\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 87.5, \"ner_token_f1\": 88.0}, \"time_spent\": \"0:01:47\", \"epochs_done\": 24, \"batches_seen\": 336, \"train_examples_seen\": 20496, \"impatience\": 7, \"patience_limit\": 7}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:52:26.85 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/word.dict]\n",
            "2020-07-29 10:52:26.89 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/tag.dict]\n",
            "2020-07-29 10:52:26.92 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/char.dict]\n",
            "2020-07-29 10:52:26.95 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n",
            "2020-07-29 10:53:10.605 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 760: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2020-07-29 10:53:10.720 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 760: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2020-07-29 10:53:12.716 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_conll2003/model_no_pos\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:53:13.264 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1424 tokens with 32 phrases; found: 33 phrases; correct: 0.\n",
            "\n",
            "precision:  87.88%; recall:  90.62%; FB1:  89.23\n",
            "\n",
            "\tcity: precision:  100.00%; recall:  100.00%; F1:  100.00 8\n",
            "\n",
            "\tcuisine: precision:  81.25%; recall:  100.00%; F1:  89.66 16\n",
            "\n",
            "\tdate: precision:  100.00%; recall:  100.00%; F1:  100.00 1\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 1\n",
            "\n",
            "\ttime: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 214, \"metrics\": {\"ner_f1\": 89.2308, \"ner_token_f1\": 90.1961}, \"time_spent\": \"0:00:01\"}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:53:13.660 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 397: processed 1846 tokens with 50 phrases; found: 53 phrases; correct: 0.\n",
            "\n",
            "precision:  77.36%; recall:  82.00%; FB1:  79.61\n",
            "\n",
            "\tcity: precision:  84.62%; recall:  84.62%; F1:  84.62 13\n",
            "\n",
            "\tcuisine: precision:  92.86%; recall:  92.86%; F1:  92.86 14\n",
            "\n",
            "\tdate: precision:  50.00%; recall:  50.00%; F1:  50.00 6\n",
            "\n",
            "\tprice_range: precision:  100.00%; recall:  100.00%; F1:  100.00 3\n",
            "\n",
            "\trestaurant_name: precision:  0.00%; recall:  0.00%; F1:  0.00 0\n",
            "\n",
            "\ttime: precision:  64.71%; recall:  84.62%; F1:  73.33 17\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"test\": {\"eval_examples_count\": 267, \"metrics\": {\"ner_f1\": 79.6117, \"ner_token_f1\": 83.0189}, \"time_spent\": \"0:00:01\"}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:53:13.986 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/word.dict]\n",
            "2020-07-29 10:53:13.989 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/tag.dict]\n",
            "2020-07-29 10:53:13.992 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/char.dict]\n",
            "2020-07-29 10:53:13.994 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n",
            "2020-07-29 10:53:57.616 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 760: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2020-07-29 10:53:57.720 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 760: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2020-07-29 10:53:59.680 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_conll2003/model_no_pos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G01hfCemaI_C",
        "colab_type": "text"
      },
      "source": [
        "Ner performs OK for everything except the restaurants' name identification.  \n",
        "That's mostly because we avoid the usage of restaurants database here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PXzLz-Jaf4I",
        "colab_type": "text"
      },
      "source": [
        "Let's check the NER performance running some slotfilling experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eKIgrOqbfgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "json.dump(ner_config, open('ner_config.json', 'wt'))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTcFFxhAbxSx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "44b2613c-57e1-4b46-9b5f-dae0ecb2737c"
      },
      "source": [
        "import json\n",
        "from deeppavlov import configs\n",
        "\n",
        "from deeppavlov.core.common.file import read_json\n",
        "from deeppavlov import build_model\n",
        "\n",
        "slotfill_config = read_json(configs.ner.slotfill_dstc2)\n",
        "slotfill_config['dataset_reader']['class_name'] = \"md_yaml_dialogs_reader\"\n",
        "slotfill_config['metadata']['variables']['DATA_PATH'] = 'schema_resto_md_yaml'\n",
        "slotfill_config['metadata']['variables']['SLOT_VALS_PATH'] = 'schema_resto_md_yaml/slotfill.json'\n",
        "slotfill_config[\"chainer\"][\"pipe\"][-1][\"load_path\"] = \"schema_resto_md_yaml/slotfill.json\"\n",
        "slotfill_config[\"metadata\"][\"variables\"][\"NER_CONFIG_PATH\"] = \"ner_config.json\"\n",
        "slotfiller = build_model(slotfill_config, download=False)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:54:00.86 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/word.dict]\n",
            "2020-07-29 10:54:00.90 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/tag.dict]\n",
            "2020-07-29 10:54:00.93 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/char.dict]\n",
            "2020-07-29 10:54:00.95 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n",
            "2020-07-29 10:54:43.643 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 760: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2020-07-29 10:54:43.747 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 760: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2020-07-29 10:54:45.772 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_conll2003/model_no_pos\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:54:45.925 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 45: Load path '/content/dp_big_demo_dir/schema_resto_md_yaml/slotfill.json' differs from save path '/root/.deeppavlov/models/slotfill_dstc2/model' in 'infer' mode for DstcSlotFillingNetwork.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6slj0dKFdXZC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6e42325f-131f-4c24-e6eb-b9e742cf7c10"
      },
      "source": [
        "slotfiller([\"i'm looking for a thai food somewhere in SFO\"])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'city': 'SFO', 'cuisine': 'Thai'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZG8Zk-ypankD",
        "colab_type": "text"
      },
      "source": [
        "Seems OK. Let's save our slotfiller config and train and evaluate the restaurants bot, finally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DKCnXjGd6Q0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "json.dump(slotfill_config, open('slotfill_config.json', 'wt'))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CkliRfVdlxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from deeppavlov import configs\n",
        "from deeppavlov.core.common.file import read_json\n",
        "\n",
        "\n",
        "gobot_config = read_json(configs.go_bot.gobot_md_yaml_minimal)\n",
        "gobot_config['chainer']['pipe'][-1]['slot_filler'] = {\"config_path\": \"slotfill_config.json\"}\n",
        "\n",
        "gobot_config['metadata']['variables']['DATA_PATH'] = 'schema_resto_md_yaml'\n",
        "gobot_config['metadata']['variables']['MODEL_PATH'] = '.'"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4HWEXlEeW92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp schema_resto_md_yaml/stories.md schema_resto_md_yaml/stories-trn.md\n",
        "!cp schema_resto_md_yaml/stories.md schema_resto_md_yaml/stories-tst.md\n",
        "!cp schema_resto_md_yaml/stories.md schema_resto_md_yaml/stories-val.md"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8dM5w1tkCgf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!echo \"{}\" > schema_resto_md_yaml/dstc2-actions2slots.json  # a hack that will be redundant in future versions. keep an empty json file in the data folder"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMbazF8ad6_N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2b247ee9-24ff-4f69-9000-0156c9be9202"
      },
      "source": [
        "from deeppavlov import train_model\n",
        "\n",
        "train_model(gobot_config, download=True);"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:54:54.943 INFO in 'deeppavlov.core.data.utils'['utils'] at line 94: Downloading from http://files.deeppavlov.ai/deeppavlov_data/slotfill_dstc2.tar.gz to /root/.deeppavlov/slotfill_dstc2.tar.gz\n",
            "100%|██████████| 641k/641k [00:00<00:00, 2.46MB/s]\n",
            "2020-07-29 10:54:55.323 INFO in 'deeppavlov.core.data.utils'['utils'] at line 269: Extracting /root/.deeppavlov/slotfill_dstc2.tar.gz archive into /root/.deeppavlov/models\n",
            "2020-07-29 10:54:56.226 INFO in 'deeppavlov.download'['download'] at line 132: Skipped http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt download because of matching hashes\n",
            "2020-07-29 10:54:56.368 INFO in 'deeppavlov.core.data.utils'['utils'] at line 94: Downloading from http://files.deeppavlov.ai/datasets/gobot_md_yaml_minimal.tar.gz to /content/dp_big_demo_dir/gobot_md_yaml_minimal.tar.gz\n",
            "100%|██████████| 472/472 [00:00<00:00, 949kB/s]\n",
            "2020-07-29 10:54:56.475 INFO in 'deeppavlov.core.data.utils'['utils'] at line 269: Extracting /content/dp_big_demo_dir/gobot_md_yaml_minimal.tar.gz archive into /content/dp_big_demo_dir/schema_resto_md_yaml\n",
            "2020-07-29 10:54:56.578 INFO in 'deeppavlov.core.data.utils'['utils'] at line 94: Downloading from http://files.deeppavlov.ai/deeppavlov_data/dstc_slot_vals.tar.gz to /content/dp_big_demo_dir/dstc_slot_vals.tar.gz\n",
            "100%|██████████| 1.62k/1.62k [00:00<00:00, 3.23MB/s]\n",
            "2020-07-29 10:54:56.680 INFO in 'deeppavlov.core.data.utils'['utils'] at line 269: Extracting /content/dp_big_demo_dir/dstc_slot_vals.tar.gz archive into /content/dp_big_demo_dir/schema_resto_md_yaml\n",
            "2020-07-29 10:54:56.776 INFO in 'deeppavlov.core.data.utils'['utils'] at line 94: Downloading from http://files.deeppavlov.ai/deeppavlov_data/ner_conll2003_v5.tar.gz to /root/.deeppavlov/ner_conll2003_v5.tar.gz\n",
            "100%|██████████| 3.12M/3.12M [00:00<00:00, 4.53MB/s]\n",
            "2020-07-29 10:54:57.560 INFO in 'deeppavlov.core.data.utils'['utils'] at line 269: Extracting /root/.deeppavlov/ner_conll2003_v5.tar.gz archive into /root/.deeppavlov/models\n",
            "2020-07-29 10:54:57.610 INFO in 'deeppavlov.dataset_readers.md_yaml_dialogs_reader'['md_yaml_dialogs_reader'] at line 123: INSIDE MLU_MD_DialogsDatasetReader._read_domain_knowledge(): reading domain knowledge from /content/dp_big_demo_dir/schema_resto_md_yaml/domain.yml\n",
            "2020-07-29 10:54:57.838 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmplb4tg62s]\n",
            "2020-07-29 10:54:57.987 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmptw79uymj]\n",
            "2020-07-29 10:54:58.156 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmpa7ceit86]\n",
            "2020-07-29 10:54:58.183 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /content/dp_big_demo_dir/word.dict]\n",
            "2020-07-29 10:54:58.186 INFO in 'deeppavlov.dataset_readers.md_yaml_dialogs_reader'['md_yaml_dialogs_reader'] at line 123: INSIDE MLU_MD_DialogsDatasetReader._read_domain_knowledge(): reading domain knowledge from /content/dp_big_demo_dir/schema_resto_md_yaml/domain.yml\n",
            "2020-07-29 10:54:58.430 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmphgvn4f7m]\n",
            "2020-07-29 10:54:58.582 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmp2n3ysq5k]\n",
            "2020-07-29 10:54:58.745 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmp2vehl0m_]\n",
            "2020-07-29 10:54:58.999 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/word.dict]\n",
            "2020-07-29 10:54:59.30 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/tag.dict]\n",
            "2020-07-29 10:54:59.32 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/char.dict]\n",
            "2020-07-29 10:54:59.35 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n",
            "2020-07-29 10:55:43.467 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 760: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2020-07-29 10:55:43.569 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 760: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2020-07-29 10:55:45.558 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_conll2003/model_no_pos\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:55:45.678 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 45: Load path '/content/dp_big_demo_dir/schema_resto_md_yaml/slotfill.json' differs from save path '/root/.deeppavlov/models/slotfill_dstc2/model' in 'infer' mode for DstcSlotFillingNetwork.\n",
            "2020-07-29 10:55:45.681 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n",
            "2020-07-29 10:56:29.802 INFO in 'deeppavlov.models.go_bot.policy.policy_network'['policy_network'] at line 89: INSIDE PolicyNetwork init(). Initializing PolicyNetwork from scratch.\n",
            "2020-07-29 10:56:33.863 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 198: Initial best per_item_action_accuracy of 0.006\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.006}, \"time_spent\": \"0:00:05\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.5682}, \"time_spent\": \"0:00:20\", \"epochs_done\": 3, \"batches_seen\": 40, \"train_examples_seen\": 311, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 1.9333688497543335}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:56:52.976 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best per_item_action_accuracy of 0.5682\n",
            "2020-07-29 10:56:52.977 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 10:56:52.978 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/dp_big_demo_dir/model/policy]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.5682}, \"time_spent\": \"0:00:24\", \"epochs_done\": 3, \"batches_seen\": 40, \"train_examples_seen\": 311, \"impatience\": 0, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.5921}, \"time_spent\": \"0:00:39\", \"epochs_done\": 7, \"batches_seen\": 80, \"train_examples_seen\": 619, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.9961247876286506}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:57:11.833 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best per_item_action_accuracy of 0.5921\n",
            "2020-07-29 10:57:11.834 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 10:57:11.840 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/dp_big_demo_dir/model/policy]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.5921}, \"time_spent\": \"0:00:43\", \"epochs_done\": 7, \"batches_seen\": 80, \"train_examples_seen\": 619, \"impatience\": 0, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6136}, \"time_spent\": \"0:00:58\", \"epochs_done\": 10, \"batches_seen\": 120, \"train_examples_seen\": 930, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.7550030320882797}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:57:30.717 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best per_item_action_accuracy of 0.6136\n",
            "2020-07-29 10:57:30.718 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 10:57:30.719 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/dp_big_demo_dir/model/policy]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6136}, \"time_spent\": \"0:01:01\", \"epochs_done\": 10, \"batches_seen\": 120, \"train_examples_seen\": 930, \"impatience\": 0, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6758}, \"time_spent\": \"0:01:16\", \"epochs_done\": 14, \"batches_seen\": 160, \"train_examples_seen\": 1238, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.6119366273283958}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:57:49.504 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best per_item_action_accuracy of 0.6758\n",
            "2020-07-29 10:57:49.505 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 10:57:49.508 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/dp_big_demo_dir/model/policy]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6758}, \"time_spent\": \"0:01:20\", \"epochs_done\": 14, \"batches_seen\": 160, \"train_examples_seen\": 1238, \"impatience\": 0, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.7033}, \"time_spent\": \"0:01:35\", \"epochs_done\": 18, \"batches_seen\": 200, \"train_examples_seen\": 1546, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.48879426941275594}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:58:08.582 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best per_item_action_accuracy of 0.7033\n",
            "2020-07-29 10:58:08.583 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
            "2020-07-29 10:58:08.588 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/dp_big_demo_dir/model/policy]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.7033}, \"time_spent\": \"0:01:39\", \"epochs_done\": 18, \"batches_seen\": 200, \"train_examples_seen\": 1546, \"impatience\": 0, \"patience_limit\": 10}}\n",
            "{\"train\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6842}, \"time_spent\": \"0:01:54\", \"epochs_done\": 21, \"batches_seen\": 240, \"train_examples_seen\": 1857, \"learning_rate\": 0.003, \"momentum\": 0.95, \"loss\": 0.4187560684978962}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:58:27.573 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the per_item_action_accuracy of 0.7033\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.6842}, \"time_spent\": \"0:01:58\", \"epochs_done\": 21, \"batches_seen\": 240, \"train_examples_seen\": 1857, \"impatience\": 1, \"patience_limit\": 10}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:58:30.565 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/dp_big_demo_dir/word.dict]\n",
            "2020-07-29 10:58:30.570 INFO in 'deeppavlov.dataset_readers.md_yaml_dialogs_reader'['md_yaml_dialogs_reader'] at line 123: INSIDE MLU_MD_DialogsDatasetReader._read_domain_knowledge(): reading domain knowledge from /content/dp_big_demo_dir/schema_resto_md_yaml/domain.yml\n",
            "2020-07-29 10:58:30.791 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmpwtaq8gbr]\n",
            "2020-07-29 10:58:30.940 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmp0j_hmxsq]\n",
            "2020-07-29 10:58:31.84 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmpi6r5mgm3]\n",
            "2020-07-29 10:58:31.337 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/word.dict]\n",
            "2020-07-29 10:58:31.367 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/tag.dict]\n",
            "2020-07-29 10:58:31.371 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/char.dict]\n",
            "2020-07-29 10:58:31.374 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n",
            "2020-07-29 10:59:14.522 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 760: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2020-07-29 10:59:14.627 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 760: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2020-07-29 10:59:16.604 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_conll2003/model_no_pos\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 10:59:16.733 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 45: Load path '/content/dp_big_demo_dir/schema_resto_md_yaml/slotfill.json' differs from save path '/root/.deeppavlov/models/slotfill_dstc2/model' in 'infer' mode for DstcSlotFillingNetwork.\n",
            "2020-07-29 10:59:16.737 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n",
            "2020-07-29 11:00:00.361 INFO in 'deeppavlov.models.go_bot.policy.policy_network'['policy_network'] at line 86: INSIDE PolicyNetwork init(). Initializing PolicyNetwork from checkpoint.\n",
            "2020-07-29 11:00:00.370 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/dp_big_demo_dir/model/policy]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/dp_big_demo_dir/model/policy\n",
            "{\"valid\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.7033}, \"time_spent\": \"0:00:05\"}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 11:00:08.525 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/dp_big_demo_dir/word.dict]\n",
            "2020-07-29 11:00:08.529 INFO in 'deeppavlov.dataset_readers.md_yaml_dialogs_reader'['md_yaml_dialogs_reader'] at line 123: INSIDE MLU_MD_DialogsDatasetReader._read_domain_knowledge(): reading domain knowledge from /content/dp_big_demo_dir/schema_resto_md_yaml/domain.yml\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{\"test\": {\"eval_examples_count\": 85, \"metrics\": {\"per_item_action_accuracy\": 0.7033}, \"time_spent\": \"0:00:04\"}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 11:00:08.755 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmpakiascde]\n",
            "2020-07-29 11:00:08.916 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmps4_56t5l]\n",
            "2020-07-29 11:00:09.70 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmplfhk6fhg]\n",
            "2020-07-29 11:00:09.315 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/word.dict]\n",
            "2020-07-29 11:00:09.347 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/tag.dict]\n",
            "2020-07-29 11:00:09.349 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/char.dict]\n",
            "2020-07-29 11:00:09.353 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n",
            "2020-07-29 11:00:53.256 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 760: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2020-07-29 11:00:53.361 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 760: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2020-07-29 11:00:55.349 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_conll2003/model_no_pos\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 11:00:55.493 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 45: Load path '/content/dp_big_demo_dir/schema_resto_md_yaml/slotfill.json' differs from save path '/root/.deeppavlov/models/slotfill_dstc2/model' in 'infer' mode for DstcSlotFillingNetwork.\n",
            "2020-07-29 11:00:55.496 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n",
            "2020-07-29 11:01:39.814 INFO in 'deeppavlov.models.go_bot.policy.policy_network'['policy_network'] at line 86: INSIDE PolicyNetwork init(). Initializing PolicyNetwork from checkpoint.\n",
            "2020-07-29 11:01:39.821 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/dp_big_demo_dir/model/policy]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/dp_big_demo_dir/model/policy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tk6inTKkeOql",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "81a47b4e-f70a-40f2-e714-3fb6b1664744"
      },
      "source": [
        "bot = build_model(gobot_config)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 11:01:40.15 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /content/dp_big_demo_dir/word.dict]\n",
            "2020-07-29 11:01:40.21 INFO in 'deeppavlov.dataset_readers.md_yaml_dialogs_reader'['md_yaml_dialogs_reader'] at line 123: INSIDE MLU_MD_DialogsDatasetReader._read_domain_knowledge(): reading domain knowledge from /content/dp_big_demo_dir/schema_resto_md_yaml/domain.yml\n",
            "2020-07-29 11:01:40.241 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmpmwa809ja]\n",
            "2020-07-29 11:01:40.383 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmppq1i2uhw]\n",
            "2020-07-29 11:01:40.523 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /tmp/tmp34i0scb1]\n",
            "2020-07-29 11:01:40.774 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/word.dict]\n",
            "2020-07-29 11:01:40.804 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/tag.dict]\n",
            "2020-07-29 11:01:40.807 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_conll2003/char.dict]\n",
            "2020-07-29 11:01:40.810 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n",
            "2020-07-29 11:02:24.335 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 760: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2020-07-29 11:02:24.444 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 760: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2020-07-29 11:02:26.449 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/ner_conll2003/model_no_pos]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_conll2003/model_no_pos\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-07-29 11:02:26.582 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 45: Load path '/content/dp_big_demo_dir/schema_resto_md_yaml/slotfill.json' differs from save path '/root/.deeppavlov/models/slotfill_dstc2/model' in 'infer' mode for DstcSlotFillingNetwork.\n",
            "2020-07-29 11:02:26.585 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n",
            "2020-07-29 11:03:10.462 INFO in 'deeppavlov.models.go_bot.policy.policy_network'['policy_network'] at line 86: INSIDE PolicyNetwork init(). Initializing PolicyNetwork from checkpoint.\n",
            "2020-07-29 11:03:10.468 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/dp_big_demo_dir/model/policy]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/dp_big_demo_dir/model/policy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2Iv0GNgfjlM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a64d3c97-7abb-45be-a9ba-91949d9eebcb"
      },
      "source": [
        "bot.reset()\n",
        "\n",
        "bot([\"Hey!\"])[0][0].actions_tuple"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('utter_hi',)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKwg9N2zbD0B",
        "colab_type": "text"
      },
      "source": [
        "Ok the bot performs OK on greeting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c-oNomgswak",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0e2ef08c-5d54-4644-abc3-6f50d1d3595b"
      },
      "source": [
        "bot([\"I'd like to find a restaurant for this evening\"])[0][0].actions_tuple"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('utter_REQUEST_City',)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxJwUqtCbJ6N",
        "colab_type": "text"
      },
      "source": [
        "The bot asks for an inevitably necessary information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otpYIs_khwPw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9aa078da-c524-4122-8f32-e2efc4c84921"
      },
      "source": [
        "bot([\"Somewhere in Oakland and for two people please\"])[0][0].actions_tuple"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('utter_OFFER_RestaurantName', 'OFFER_City')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4Ab-S4WbUJL",
        "colab_type": "text"
      },
      "source": [
        "The suggests some restaurant but since no actual DB usage happened that's just the fact that the bot knows that some slots are enough to book a table."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51ViTAFjtZTq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8fec60ea-03dd-4cf3-fa4d-fb8243488680"
      },
      "source": [
        "bot([\"Cool! That's what I was looking for, thanks!\"])[0][0].actions_tuple"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('utter_INFORM_HasLiveMusic',)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIgU4aSSbmlS",
        "colab_type": "text"
      },
      "source": [
        "Let's say goodbye to our bot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNrBveyzhw7V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7b690682-964d-4de3-9795-4df692e71f0b"
      },
      "source": [
        "bot([\"Bye bot\"])[0][0].actions_tuple"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('utter_REQUEST_Time',)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B--vLcEBbpRp",
        "colab_type": "text"
      },
      "source": [
        "After the goodbye bot does perform uninterpretable. That's what most of recurrent system do after the end of the sequence cause no one reaches that poing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4ASqT_Fu4TH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "c675cd2c-7849-4426-a14f-9d9cc93a8658"
      },
      "source": [
        "bot([\"Bye bot\"])[0][0].actions_tuple"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('utter_CONFIRM_RestaurantName',\n",
              " 'CONFIRM_City',\n",
              " 'CONFIRM_Time',\n",
              " 'CONFIRM_Date',\n",
              " 'CONFIRM_PartySize')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ug6-3fYwb-BX",
        "colab_type": "text"
      },
      "source": [
        "## Final words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzcVEXleb_aU",
        "colab_type": "text"
      },
      "source": [
        "More of in-depth examples of goal-oriented bots and their features are coming with future releases, stay tuned!"
      ]
    }
  ]
}